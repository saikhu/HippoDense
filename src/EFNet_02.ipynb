{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D classification example based on DenseNet\n",
    "\n",
    "This tutorial shows an example of 3D classification task based on DenseNet and array format transforms.\n",
    "\n",
    "Here, the task is given to classify MR images into male/female.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/3d_classification/torch/densenet_training_array.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.1+253.ge8d2d4f4\n",
      "Numpy version: 1.22.3\n",
      "Pytorch version: 1.12.0a0+bd13bc6\n",
      "MONAI flags: HAS_EXT = True, USE_COMPILED = False\n",
      "MONAI rev id: e8d2d4f4018217347dc41b8b87eb13bfe75bf3be\n",
      "MONAI __file__: /opt/monai/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.2\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: 2.8.0\n",
      "gdown version: 4.4.0\n",
      "TorchVision version: 0.13.0a0\n",
      "tqdm version: 4.64.0\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.4.1\n",
      "transformers version: 4.19.1\n",
      "mlflow version: 1.25.1\n",
      "pynrrd version: 0.4.3\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "import monai\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, ImageDataset\n",
    "from monai.transforms import (\n",
    "    AddChannel,\n",
    "    Compose,\n",
    "    RandRotate90,\n",
    "    Resize,\n",
    "    ScaleIntensity,\n",
    "    EnsureType\n",
    ")\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "pin_memory = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115: images cannot be used.\n",
      "251: total images prepared with 2 different classes\n"
     ]
    }
   ],
   "source": [
    "# set this in your environment or previous cell to wherever IXI is downloaded and extracted\n",
    "modelName = 'EfficientNet_Repeat'\n",
    "RunFolder = os.path.join(\"/HippoDense/\", modelName)\n",
    "DatasetDir = \"/Datasets/01_P_Classification_all_hippo\"\n",
    "labels = []\n",
    "images = []\n",
    "NotFitImages = []\n",
    "for root, dirs, files in os.walk(os.path.abspath(DatasetDir)):\n",
    "    for file in files:\n",
    "        # if file.split(\"_\")[-3] == \"L\":\n",
    "        #     labels.append(2)\n",
    "        #     images.append(os.path.join(root, file))\n",
    "        # elif file.split(\"_\")[-3] == \"E\":\n",
    "        #     labels.append(1)\n",
    "        #     images.append(os.path.join(root, file))\n",
    "        if file.split(\"_\")[-2] == \"Normal\":\n",
    "            labels.append('Normal')\n",
    "            images.append(os.path.join(root, file))\n",
    "        elif file.split(\"_\")[-2] == \"Dementia\":\n",
    "            labels.append('Dementia')\n",
    "            images.append(os.path.join(root, file))\n",
    "        else:\n",
    "            NotFitImages.append(file)\n",
    "            # print(file)\n",
    "print(\"{}: images cannot be used.\".format(len(NotFitImages)))\n",
    "# # labels = np.load(\n",
    "#     '/workspace/monai/MONAI-tutorials/3d_classification/01_P_Classification_all_labels.npy')\n",
    "NumClasses = len(np.unique(labels))\n",
    "# ClassLabels = np.array(Labels)\n",
    "if len(images)==len(labels):\n",
    "    print(\"{}: total images prepared with {} different classes\".format(len(images), NumClasses))\n",
    "\n",
    "# 2 binary labels for gender classification: man or woman\n",
    "# labels = np.array([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "\n",
    "# Represent labels in one-hot format for binary classifier training,\n",
    "# BCEWithLogitsLoss requires target to have same shape as input\n",
    "# labels = torch.nn.functional.one_hot(torch.as_tensor(labels)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "\n",
    "train_transforms = Compose([ScaleIntensity(), AddChannel(), Resize((224, 224, 224)), RandRotate90(), EnsureType()])\n",
    "val_transforms = Compose([ScaleIntensity(), AddChannel(), Resize((224, 224, 224)), EnsureType()])\n",
    "\n",
    "# train_transforms = Compose([ScaleIntensity(), AddChannel(), Resize((96, 96, 96)), RandRotate90(), EnsureType()])\n",
    "# val_transforms = Compose([ScaleIntensity(), AddChannel(), Resize((96, 96, 96)), EnsureType()])\n",
    "\n",
    "# Define nifti dataset, data loader\n",
    "check_ds = ImageDataset(image_files=images, labels=labels, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=3, num_workers=2, pin_memory=pin_memory)\n",
    "\n",
    "im, label = monai.utils.misc.first(check_loader)\n",
    "# print(type(im), im.shape, label, label.shape)\n",
    "\n",
    "# create a training data loader\n",
    "train_ds = ImageDataset(image_files=images[:200], labels=labels[:200], transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0, pin_memory=pin_memory)\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = ImageDataset(image_files=images[200:], labels=labels[200:], transform=val_transforms)\n",
    "# val_loader = DataLoader(val_ds, batch_size=4, num_workers=4, pin_memory=pin_memory)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=0, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/150\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/HippoDense/src/EFNet_02.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6164436c617373696669636174696f6e486970706f44222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/HippoDense/src/EFNet_02.ipynb#ch0000009vscode-remote?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_data \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6164436c617373696669636174696f6e486970706f44222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/HippoDense/src/EFNet_02.ipynb#ch0000009vscode-remote?line=29'>30</a>\u001b[0m     step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6164436c617373696669636174696f6e486970706f44222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/HippoDense/src/EFNet_02.ipynb#ch0000009vscode-remote?line=30'>31</a>\u001b[0m     inputs, labels \u001b[39m=\u001b[39m batch_data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), batch_data[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6164436c617373696669636174696f6e486970706f44222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/HippoDense/src/EFNet_02.ipynb#ch0000009vscode-remote?line=31'>32</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6164436c617373696669636174696f6e486970706f44222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/HippoDense/src/EFNet_02.ipynb#ch0000009vscode-remote?line=32'>33</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "# model = monai.networks.nets.DenseNet264(spatial_dims=3, in_channels=1, out_channels=2, growth_rate = 40).to(device)\n",
    "\n",
    "model = monai.networks.nets.EfficientNetBN('efficientnet-b1', spatial_dims=3, in_channels=1, num_classes=2).to(device)\n",
    "\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "# loss_function = torch.nn.BCEWithLogitsLoss()  # also works with this data\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "\n",
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "writer = SummaryWriter(modelName)\n",
    "max_epochs = 150\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        print\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "\n",
    "        num_correct = 0.0\n",
    "        metric_count = 0\n",
    "        for val_data in val_loader:\n",
    "            val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(val_images)\n",
    "                value = torch.eq(val_outputs.argmax(dim=1), val_labels.argmax(dim=1))\n",
    "                metric_count += len(value)\n",
    "                num_correct += value.sum().item()\n",
    "\n",
    "        metric = num_correct / metric_count\n",
    "        metric_values.append(metric)\n",
    "\n",
    "        if metric > best_metric:\n",
    "            best_metric = metric\n",
    "            best_metric_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), \"best_metric_model_classification3d_array.pth\")\n",
    "            modelPickle = os.path.join(RunFolder, modelName + time.strftime(\"_%Y%m%d_%H%M%S\") + '.pickle')\n",
    "            if not os.path.exists(RunFolder):\n",
    "                os.makedirs(RunFolder)\n",
    "            \n",
    "            with open(modelPickle, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "            f.close()\n",
    "            print(\"saved new best metric model = {}\".format(modelPickle))\n",
    "\n",
    "        print(f\"Current epoch: {epoch+1} current accuracy: {metric:.4f} \")\n",
    "        print(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
    "        writer.add_scalar(\"val_accuracy\", metric, epoch + 1)\n",
    "\n",
    "print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0].to(device),\n",
    "            test_data[1].to(device),\n",
    "        )\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n",
    "print(classification_report(\n",
    "    y_true, y_pred, target_names=class_names, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occlusion sensitivity\n",
    "One method for trying to visualise why the network made a given prediction is occlusion sensitivity. We occlude part of the image, and see how the probability of a given prediction changes. We then iterate over the image, moving the occluded portion as we go, and in doing so we build up a sensitivity map detailing which areas were the most important in making the decision.\n",
    "\n",
    "#### Bounds\n",
    "If we were to test the occlusion centred on all voxels in our image, we would have to do `torch.prod(im.shape) = 96^3 = ~1e6` predictions. We can use the bounding box to only to the estimations in a region of interest, for example over one slice.\n",
    "\n",
    "To do this, we simply give the bounding box as `(minC,maxC,minD,maxD,minH,maxH,minW,maxW)`. We can use `-1` for any value to use its full extent (`0` and `im.shape-1` for min's and max's, respectively).\n",
    "\n",
    "#### Output\n",
    "The output image in this example will look fairly bad, since our network hasn't been trained for very long. Training for longer should improve the quality of the occlusion map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model\n",
    "On given data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "modelPickle = \"/HippoDense/EfficientNet/EfficientNet_20220603_035507.pickle\"\n",
    "savedModel = open(modelPickle, 'rb')\n",
    "trainedModel = pickle.load(savedModel)\n",
    "savedModel.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a validation data loader\n",
    "test_ds = ImageDataset(image_files=images[-10:], labels=labels[-10:], transform=val_transforms)\n",
    "test_loader = DataLoader(val_ds, batch_size=1, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "itera = iter(test_loader)\n",
    "\n",
    "\n",
    "def get_next_im():\n",
    "    test_data = next(itera)\n",
    "    return test_data[0].to(device), test_data[1].unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "def plot_occlusion_heatmap(im, heatmap):\n",
    "    plt.subplots(1, 2)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.squeeze(im.cpu()))\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(heatmap)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time for image 1 is 0.040650129318237305 sec\n",
      "**** (tensor([[ 2.6070, -2.4342]], device='cuda:0'), tensor([[0., 1.]], device='cuda:0'))\n",
      "Execution Time for image 2 is 0.04082989692687988 sec\n",
      "**** (tensor([[ 2.5677, -2.1427]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 3 is 0.0403437614440918 sec\n",
      "**** (tensor([[ 0.8322, -1.0477]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 4 is 0.04065418243408203 sec\n",
      "**** (tensor([[ 2.4559, -2.3681]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 5 is 0.04034113883972168 sec\n",
      "**** (tensor([[ 2.8965, -2.5164]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 6 is 0.0402529239654541 sec\n",
      "**** (tensor([[ 2.8985, -2.4217]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 7 is 0.040856122970581055 sec\n",
      "**** (tensor([[ 1.1098, -1.3855]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 8 is 0.04070854187011719 sec\n",
      "**** (tensor([[ 2.6966, -2.4582]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 9 is 0.04066157341003418 sec\n",
      "**** (tensor([[ 2.6034, -2.2085]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 10 is 0.04073190689086914 sec\n",
      "**** (tensor([[ 2.9163, -2.4555]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 11 is 0.040506601333618164 sec\n",
      "**** (tensor([[ 1.0107, -1.1501]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 12 is 0.04080772399902344 sec\n",
      "**** (tensor([[ 2.2102, -2.2106]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 13 is 0.041207313537597656 sec\n",
      "**** (tensor([[ 2.5943, -2.2429]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 14 is 0.041253089904785156 sec\n",
      "**** (tensor([[ 2.7024, -2.4256]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 15 is 0.041249752044677734 sec\n",
      "**** (tensor([[ 2.9214, -2.5085]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 16 is 0.041239261627197266 sec\n",
      "**** (tensor([[ 2.9347, -2.4148]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 17 is 0.04111456871032715 sec\n",
      "**** (tensor([[ 2.9563, -2.4496]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 18 is 0.04105949401855469 sec\n",
      "**** (tensor([[ 2.9652, -2.4988]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 19 is 0.04106259346008301 sec\n",
      "**** (tensor([[ 2.9229, -2.4382]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 20 is 0.04099011421203613 sec\n",
      "**** (tensor([[ 2.7344, -2.5144]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 21 is 0.041060447692871094 sec\n",
      "**** (tensor([[ 2.3201, -2.1513]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 22 is 0.04124855995178223 sec\n",
      "**** (tensor([[ 2.6992, -2.1586]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 23 is 0.041129350662231445 sec\n",
      "**** (tensor([[ 2.4300, -2.2825]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 24 is 0.05652213096618652 sec\n",
      "**** (tensor([[ 2.9518, -2.4406]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 25 is 0.04448580741882324 sec\n",
      "**** (tensor([[ 2.7764, -2.1985]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 26 is 0.041117191314697266 sec\n",
      "**** (tensor([[ 2.9595, -2.5744]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 27 is 0.04115605354309082 sec\n",
      "**** (tensor([[ 2.7864, -2.3119]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 28 is 0.04138994216918945 sec\n",
      "**** (tensor([[ 2.7398, -2.3893]], device='cuda:0'), tensor([[0., 1.]], device='cuda:0'))\n",
      "Execution Time for image 29 is 0.04123687744140625 sec\n",
      "**** (tensor([[ 2.8585, -2.5493]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 30 is 0.059850215911865234 sec\n",
      "**** (tensor([[ 2.5734, -2.4116]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 31 is 0.04311704635620117 sec\n",
      "**** (tensor([[ 1.0867, -1.1800]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 32 is 0.04160618782043457 sec\n",
      "**** (tensor([[ 2.8338, -2.4879]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 33 is 0.04159975051879883 sec\n",
      "**** (tensor([[ 2.8765, -2.3920]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 34 is 0.04125523567199707 sec\n",
      "**** (tensor([[ 2.0350, -1.9827]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 35 is 0.041326045989990234 sec\n",
      "**** (tensor([[-0.0040,  0.0796]], device='cuda:0'), tensor([[0., 1.]], device='cuda:0'))\n",
      "Execution Time for image 36 is 0.04867863655090332 sec\n",
      "**** (tensor([[-0.9997,  1.4483]], device='cuda:0'), tensor([[0., 1.]], device='cuda:0'))\n",
      "Execution Time for image 37 is 0.04145550727844238 sec\n",
      "**** (tensor([[ 2.6291, -2.4438]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 38 is 0.041510820388793945 sec\n",
      "**** (tensor([[ 3.0485, -2.5259]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 39 is 0.04177737236022949 sec\n",
      "**** (tensor([[ 2.5296, -2.2657]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 40 is 0.0419163703918457 sec\n",
      "**** (tensor([[ 2.9114, -2.4768]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 41 is 0.04185199737548828 sec\n",
      "**** (tensor([[ 2.5119, -2.1915]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 42 is 0.04197406768798828 sec\n",
      "**** (tensor([[ 1.8814, -2.1457]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 43 is 0.04194211959838867 sec\n",
      "**** (tensor([[ 2.8285, -2.4651]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 44 is 0.04169464111328125 sec\n",
      "**** (tensor([[ 2.7586, -2.4012]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 45 is 0.04202461242675781 sec\n",
      "**** (tensor([[ 1.9472, -1.8544]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 46 is 0.041600704193115234 sec\n",
      "**** (tensor([[ 2.9967, -2.5934]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 47 is 0.04193997383117676 sec\n",
      "**** (tensor([[ 2.4642, -2.3442]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 48 is 0.041574716567993164 sec\n",
      "**** (tensor([[ 2.9381, -2.4422]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 49 is 0.04185295104980469 sec\n",
      "**** (tensor([[ 2.4166, -2.1689]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 50 is 0.04190850257873535 sec\n",
      "**** (tensor([[ 2.9439, -2.5624]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Execution Time for image 51 is 0.041814565658569336 sec\n",
      "**** (tensor([[ 2.0945, -2.0054]], device='cuda:0'), tensor([[1., 0.]], device='cuda:0'))\n",
      "Accuracy of the model based on the test set of 50 inputs is: 98 %\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "metric_count = -1\n",
    "num_correct = 0\n",
    "numImages = 251\n",
    "\n",
    "running_accuracy = 0 \n",
    "total = 0 \n",
    "trainedModel.eval()\n",
    "i = 1\n",
    "for val_data in val_loader:\n",
    "    timestart = time.time()\n",
    "    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "    with torch.no_grad():\n",
    "        val_outputs = trainedModel(val_images)\n",
    "        value = torch.eq(val_outputs.argmax(dim=1), val_labels.argmax(dim=1))\n",
    "        metric_count += len(value)\n",
    "        num_correct += value.sum().item()\n",
    "        # print(val_outputs)\n",
    "        \n",
    "        # predicted_outputs = trainedModel(val_images)\n",
    "        # _ , predicted = torch.max(predicted_outputs, 1) \n",
    "        # total += val_labels.size(0) \n",
    "        # running_accuracy += (predicted == val_labels).sum().item() \n",
    "        print(\"Execution Time for image {} is {} sec\".format(i, (time.time() - timestart)))\n",
    "        print(\"****\", (val_outputs , val_labels))\n",
    "        i += 1\n",
    "\n",
    "print('Accuracy of the model based on the test set of', metric_count ,'inputs is: %d %%' % (100 * num_correct / metric_count))\n",
    "# print(\"Accuracy Min = \", (100 * num_correct /numImages ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 256, 208]) torch.Size([1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "tt = Compose([ScaleIntensity()])\n",
    "t_ds = ImageDataset(image_files=images, labels=labels)\n",
    "t_loader = DataLoader(t_ds, batch_size=1)\n",
    "iterat = iter(t_loader)\n",
    "\n",
    "\n",
    "def get_next_im():\n",
    "    t_data = next(iterat)\n",
    "    return t_data[0].to(device), t_data[1].unsqueeze(0).to(device)\n",
    "imgT, labelT = get_next_im()\n",
    "print(imgT.shape, labelT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/HippoDense/DenseNet256_40.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6164436c617373696669636174696f6e486970706f44222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/HippoDense/DenseNet256_40.ipynb#ch0000017vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6164436c617373696669636174696f6e486970706f44222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/HippoDense/DenseNet256_40.ipynb#ch0000017vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# pathNifti = \"/home/usman/Desktop/Datasets/dldirect_results/seg_Right-Hippocampus.nii.gz\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6164436c617373696669636174696f6e486970706f44222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/HippoDense/DenseNet256_40.ipynb#ch0000017vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# img = image.load_img(pathNifti)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6164436c617373696669636174696f6e486970706f44222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/HippoDense/DenseNet256_40.ipynb#ch0000017vscode-remote?line=4'>5</a>\u001b[0m plotting\u001b[39m.\u001b[39;49mplot_glass_brain(imgT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/nilearn/plotting/img_plotting.py:1030\u001b[0m, in \u001b[0;36mplot_glass_brain\u001b[0;34m(stat_map_img, output_file, display_mode, colorbar, cbar_tick_format, figure, axes, title, threshold, annotate, black_bg, cmap, alpha, vmin, vmax, plot_abs, symmetric_cbar, resampling_interpolation, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/nilearn/plotting/img_plotting.py?line=1026'>1027</a>\u001b[0m \u001b[39mif\u001b[39;00m cmap \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/nilearn/plotting/img_plotting.py?line=1027'>1028</a>\u001b[0m     cmap \u001b[39m=\u001b[39m cm\u001b[39m.\u001b[39mcold_hot \u001b[39mif\u001b[39;00m black_bg \u001b[39melse\u001b[39;00m cm\u001b[39m.\u001b[39mcold_white_hot\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/nilearn/plotting/img_plotting.py?line=1029'>1030</a>\u001b[0m \u001b[39mif\u001b[39;00m stat_map_img:\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/nilearn/plotting/img_plotting.py?line=1030'>1031</a>\u001b[0m     stat_map_img \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mcheck_niimg_3d(stat_map_img, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/nilearn/plotting/img_plotting.py?line=1031'>1032</a>\u001b[0m     \u001b[39mif\u001b[39;00m plot_abs:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "from nilearn import plotting, image\n",
    "import numpy as np\n",
    "# pathNifti = \"/home/usman/Desktop/Datasets/dldirect_results/seg_Right-Hippocampus.nii.gz\"\n",
    "# img = image.load_img(pathNifti)\n",
    "plotting.plot_glass_brain(imgT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = plotting.view_img_on_surf(img, threshold='80%', cmap=nilearn_cmaps['cold_hot'])\n",
    "# view.open_in_browser()\n",
    "\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing occlusion sensitivity: 100%|██████████| 64/64 [00:00<00:00, 228.46it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1080 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the occlusion sensitivity map\n",
    "occ_sens = monai.visualize.OcclusionSensitivity(nn_module=trainedModel, mask_size=12, n_batch=10, stride=12)\n",
    "# Only get a single slice to save time.\n",
    "# For the other dimensions (channel, width, height), use\n",
    "# -1 to use 0 and img.shape[x]-1 for min and max, respectively\n",
    "depth_slice = img.shape[3] // 2\n",
    "occ_sens_b_box = [-1, -1, depth_slice, depth_slice, -1, -1, -1, -1]\n",
    "\n",
    "occ_result, _ = occ_sens(x=img, b_box=occ_sens_b_box)\n",
    "occ_result = occ_result[..., label.argmax().item()]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(25, 15), facecolor=\"white\")\n",
    "\n",
    "for i, im in enumerate([img[:, :, 50, ...], occ_result]):\n",
    "    cmap = \"gray\" if i == 0 else \"jet\"\n",
    "    ax = axes[i]\n",
    "    im_show = ax.imshow(np.squeeze(im[0][0].detach().cpu()), cmap=cmap)\n",
    "    ax.axis(\"off\")\n",
    "    fig.colorbar(im_show, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup data directory\n",
    "\n",
    "Remove directory if a temporary was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
