/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
MONAI version: 0.8.1+253.ge8d2d4f4
Numpy version: 1.22.3
Pytorch version: 1.12.0a0+bd13bc6
MONAI flags: HAS_EXT = True, USE_COMPILED = False
MONAI rev id: e8d2d4f4018217347dc41b8b87eb13bfe75bf3be
MONAI __file__: /opt/monai/monai/__init__.py
Optional dependencies:
Pytorch Ignite version: 0.4.8
Nibabel version: 3.2.2
scikit-image version: 0.19.2
Pillow version: 9.0.1
Tensorboard version: 2.8.0
gdown version: 4.4.0
TorchVision version: 0.13.0a0
tqdm version: 4.64.0
lmdb version: 1.3.0
psutil version: 5.9.0
pandas version: 1.3.5
einops version: 0.4.1
transformers version: 4.19.1
mlflow version: 1.25.1
pynrrd version: 0.4.3
For details about installing the optional dependencies, please visit:
    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies
2: images cannot be used.
364: total images prepared with 4 different classes
/Datasets/01_P_Classification_all_hippo/01_P_1744_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2125_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1974_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0032_1_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1678_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0068_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1855_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1947_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1673_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1916_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1857_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2031_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2064_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2130_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1791_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1827_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2136_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2005_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1834_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1838_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0096_3_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2009_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1956_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0497_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2101_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2164_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1693_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1726_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1691_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2015_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2121_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2037_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0068_3_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1805_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1914_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1928_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2002_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2034_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1870_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2008_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0758_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0007_1_E_MCI_hippo.nii tensor([0., 1., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0467_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2106_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2046_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1756_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0364_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2019_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2071_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0297_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2026_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1919_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1734_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2080_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0165_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0004_1_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1897_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1464_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2148_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1994_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2077_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1979_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0209_1_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2060_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0189_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2035_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2139_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1687_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1969_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1683_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0096_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2087_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1670_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0450_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0029_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1862_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1818_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1853_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1902_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2042_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2155_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0768_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1402_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0448_E_MCI_hippo.nii tensor([0., 1., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0175_1_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1714_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1833_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0124_6_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0397_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1730_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1672_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1107_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0803_1_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2049_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1815_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0668_1_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1984_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1877_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0076_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0332_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1831_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1970_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2012_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2014_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2040_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0407_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0161_2_E_MCI_hippo.nii tensor([0., 1., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1588_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1677_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0355_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0005_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1910_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2096_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2114_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2107_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1730_2_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1757_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2010_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2105_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2160_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1905_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1023_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2007_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1924_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2112_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0192_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2092_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2120_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2146_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1920_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1903_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2051_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1837_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2061_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0051_2_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2004_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0173_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0034_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1606_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2118_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1508_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1883_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1997_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2157_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2093_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1803_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1907_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2082_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1933_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2081_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1971_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1908_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2033_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1766_2_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2056_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0276_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2074_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1735_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2030_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2141_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2024_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2149_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1894_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1772_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1872_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0814_1_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1939_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1976_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1817_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2088_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1404_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0191_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1957_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0031_E_MCI_hippo.nii tensor([0., 1., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0248_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1884_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1701_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2017_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0457_1_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0198_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1598_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1930_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2158_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1995_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1852_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1732_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0267_2_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0829_1_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1992_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1958_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0188_E_MCI_hippo.nii tensor([0., 1., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0017_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1964_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0159_1_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2044_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1755_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1869_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1959_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1715_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1832_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1754_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1733_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1736_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0096_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1942_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0657_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1749_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1926_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1991_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2128_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2115_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1868_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1579_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0457_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0278_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0255_1_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0065_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2127_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1491_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1881_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2095_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1856_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1727_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2021_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2001_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2150_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0331_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1840_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1962_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1990_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0138_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1925_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0154_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1835_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0155_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1751_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2073_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1821_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2143_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2066_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0308_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1790_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1847_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2094_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2156_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2053_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1753_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0185_1_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1731_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1909_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1587_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0100_1_E_MCI_hippo.nii tensor([0., 1., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1809_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2138_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0013_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0056_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1989_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0077_2_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2124_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1904_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2131_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1713_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2091_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1700_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0313_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1887_2_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0252_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1400_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1851_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0159_2_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1886_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1801_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1980_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0006_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1675_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2110_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2062_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1880_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1722_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1699_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1482_E_MCI_hippo.nii tensor([0., 1., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1850_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2011_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0398_2_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1929_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1891_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2000_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1774_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1816_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2072_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2152_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0019_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2029_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2117_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0481_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0256_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2055_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2043_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1813_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0255_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2013_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0051_1_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1210_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2052_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1799_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1981_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1906_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1885_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1960_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1748_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0068_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0024_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1737_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0166_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1899_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0267_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2025_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1702_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0141_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2063_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1888_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2097_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1738_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2147_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1729_2_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0301_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1901_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1874_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1861_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0075_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1993_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2048_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1895_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1684_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1759_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1953_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1709_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2047_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1791_1_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0169_2_Dementia_hippo.nii tensor([1., 0., 0., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1918_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2100_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0063_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1819_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0429_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_0155_2_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2020_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_2068_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2145_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1797_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2070_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_2089_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0769_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1746_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0010_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1828_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0247_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1966_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0776_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1830_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_0170_1_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1911_Normal_hippo.nii tensor([0., 0., 0., 1.])
/Datasets/01_P_Classification_all_hippo/01_P_1983_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
/Datasets/01_P_Classification_all_hippo/01_P_1951_L_MCI_hippo.nii tensor([0., 0., 1., 0.])
<class 'torch.Tensor'> torch.Size([3, 1, 224, 224, 224]) tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]]) torch.Size([3, 4])
<class 'torch.Tensor'> torch.Size([3, 1, 224, 224, 224]) tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]]) torch.Size([3, 4])
----------
epoch 1/150
1/300, train_loss: 0.4028
2/300, train_loss: 6.4652
3/300, train_loss: 6.5435
4/300, train_loss: 4.9519
5/300, train_loss: 7.4345
6/300, train_loss: 6.2239
7/300, train_loss: 3.5115
8/300, train_loss: 5.8857
9/300, train_loss: 6.5669
10/300, train_loss: 1.6759
11/300, train_loss: 7.8864
12/300, train_loss: 4.1246
13/300, train_loss: 1.5739
14/300, train_loss: 1.0233
15/300, train_loss: 4.5999
16/300, train_loss: 3.1115
17/300, train_loss: 8.7257
18/300, train_loss: 3.8514
19/300, train_loss: 3.1573
20/300, train_loss: 5.7080
21/300, train_loss: 1.9355
22/300, train_loss: 1.9715
23/300, train_loss: 4.6948
24/300, train_loss: 1.2961
25/300, train_loss: 3.4356
26/300, train_loss: 4.4357
27/300, train_loss: 5.7245
28/300, train_loss: 5.2892
29/300, train_loss: 5.8369
30/300, train_loss: 6.0851
31/300, train_loss: 5.7172
32/300, train_loss: 0.6259
33/300, train_loss: 6.6598
34/300, train_loss: 2.7930
35/300, train_loss: 6.1087
36/300, train_loss: 7.3165
37/300, train_loss: 0.6070
38/300, train_loss: 2.0581
39/300, train_loss: 3.9121
40/300, train_loss: 4.0899
41/300, train_loss: 1.0933
42/300, train_loss: 3.6300
43/300, train_loss: 6.7847
44/300, train_loss: 6.9152
45/300, train_loss: 3.7622
46/300, train_loss: 3.5195
47/300, train_loss: 4.9975
48/300, train_loss: 1.1710
49/300, train_loss: 4.2322
50/300, train_loss: 3.7206
51/300, train_loss: 5.7762
52/300, train_loss: 0.9404
53/300, train_loss: 2.2723
54/300, train_loss: 1.1100
55/300, train_loss: 4.4467
56/300, train_loss: 4.7121
57/300, train_loss: 0.2958
58/300, train_loss: 1.9218
59/300, train_loss: 6.4257
60/300, train_loss: 6.4496
61/300, train_loss: 4.3884
62/300, train_loss: 3.1624
63/300, train_loss: 6.0960
64/300, train_loss: 1.4446
65/300, train_loss: 1.3959
66/300, train_loss: 3.0958
67/300, train_loss: 1.0248
68/300, train_loss: 0.8141
69/300, train_loss: 6.9837
70/300, train_loss: 4.7976
71/300, train_loss: 2.2828
72/300, train_loss: 2.2006
73/300, train_loss: 2.1377
74/300, train_loss: 6.6406
75/300, train_loss: 4.5981
76/300, train_loss: 0.6033
77/300, train_loss: 4.7357
78/300, train_loss: 8.9807
79/300, train_loss: 8.3133
80/300, train_loss: 0.0954
81/300, train_loss: 3.3812
82/300, train_loss: 2.7147
83/300, train_loss: 2.7956
84/300, train_loss: 3.6843
85/300, train_loss: 2.9308
86/300, train_loss: 6.2542
87/300, train_loss: 4.3206
88/300, train_loss: 4.1645
89/300, train_loss: 6.7324
90/300, train_loss: 1.4305
91/300, train_loss: 4.9135
92/300, train_loss: 8.6799
93/300, train_loss: 4.5513
94/300, train_loss: 7.8261
95/300, train_loss: 0.0451
96/300, train_loss: 8.4978
97/300, train_loss: 2.5188
98/300, train_loss: 6.7150
99/300, train_loss: 7.5048
100/300, train_loss: 1.0728
101/300, train_loss: 5.5202
102/300, train_loss: 4.6363
103/300, train_loss: 6.6628
104/300, train_loss: 7.8161
105/300, train_loss: 1.3668
106/300, train_loss: 2.6905
107/300, train_loss: 1.9520
108/300, train_loss: 10.6660
109/300, train_loss: 3.8168
110/300, train_loss: 1.6802
111/300, train_loss: 7.3685
112/300, train_loss: 5.6170
113/300, train_loss: 10.1676
114/300, train_loss: 3.8054
115/300, train_loss: 4.2655
116/300, train_loss: 2.5155
117/300, train_loss: 2.7610
118/300, train_loss: 6.4189
119/300, train_loss: 3.8581
120/300, train_loss: 7.1840
121/300, train_loss: 0.2584
122/300, train_loss: 5.8135
123/300, train_loss: 2.1690
124/300, train_loss: 5.7168
125/300, train_loss: 3.0548
126/300, train_loss: 5.0932
127/300, train_loss: 6.4274
128/300, train_loss: 3.3179
129/300, train_loss: 5.1768
130/300, train_loss: 2.2401
131/300, train_loss: 4.7572
132/300, train_loss: 5.5623
133/300, train_loss: 3.2983
134/300, train_loss: 1.0347
135/300, train_loss: 6.0259
136/300, train_loss: 2.7868
137/300, train_loss: 0.8706
138/300, train_loss: 7.1507
139/300, train_loss: 2.9229
140/300, train_loss: 4.2216
141/300, train_loss: 4.1923
142/300, train_loss: 2.8285
143/300, train_loss: 1.7350
144/300, train_loss: 3.2008
145/300, train_loss: 4.3166
146/300, train_loss: 2.7005
147/300, train_loss: 5.6216
148/300, train_loss: 1.1590
149/300, train_loss: 3.4450
150/300, train_loss: 7.3518
151/300, train_loss: 3.6444
152/300, train_loss: 3.4255
153/300, train_loss: 4.0969
154/300, train_loss: 2.5654
155/300, train_loss: 7.6457
156/300, train_loss: 1.1839
157/300, train_loss: 6.7291
158/300, train_loss: 5.1237
159/300, train_loss: 1.7323
160/300, train_loss: 2.0344
161/300, train_loss: 3.0089
162/300, train_loss: 5.5017
163/300, train_loss: 4.7272
164/300, train_loss: 4.1103
165/300, train_loss: 9.4391
166/300, train_loss: 8.9225
167/300, train_loss: 5.5347
168/300, train_loss: 4.0314
169/300, train_loss: 8.7920
170/300, train_loss: 4.9917
171/300, train_loss: 10.3813
172/300, train_loss: 4.2342
173/300, train_loss: 4.3784
174/300, train_loss: 3.4545
175/300, train_loss: 2.5318
176/300, train_loss: 3.0598
177/300, train_loss: 4.3950
178/300, train_loss: 2.6283
179/300, train_loss: 1.8041
180/300, train_loss: 0.8731
181/300, train_loss: 6.4514
182/300, train_loss: 7.3278
183/300, train_loss: 0.5991
184/300, train_loss: 0.5518
185/300, train_loss: 2.5351
186/300, train_loss: 5.6104
187/300, train_loss: 1.4906
188/300, train_loss: 3.1962
189/300, train_loss: 5.6403
190/300, train_loss: 4.9621
191/300, train_loss: 3.3925
192/300, train_loss: 9.3677
193/300, train_loss: 9.5441
194/300, train_loss: 1.1233
195/300, train_loss: 7.2563
196/300, train_loss: 2.6644
197/300, train_loss: 7.2570
198/300, train_loss: 0.2026
199/300, train_loss: 3.5042
200/300, train_loss: 3.4090
201/300, train_loss: 0.7491
202/300, train_loss: 3.6038
203/300, train_loss: 1.6641
204/300, train_loss: 8.4501
205/300, train_loss: 3.0869
206/300, train_loss: 6.5963
207/300, train_loss: 4.1134
208/300, train_loss: 2.4105
209/300, train_loss: 1.9956
210/300, train_loss: 5.9079
211/300, train_loss: 0.7171
212/300, train_loss: 1.5650
213/300, train_loss: 3.5646
214/300, train_loss: 4.3817
215/300, train_loss: 2.4403
216/300, train_loss: 4.9332
217/300, train_loss: 10.4107
218/300, train_loss: 1.6320
219/300, train_loss: 7.7949
220/300, train_loss: 0.5016
221/300, train_loss: 6.1612
222/300, train_loss: 2.7350
223/300, train_loss: 1.6686
224/300, train_loss: 0.2775
225/300, train_loss: 1.3629
226/300, train_loss: 5.9070
227/300, train_loss: 1.3972
228/300, train_loss: 5.8730
229/300, train_loss: 2.4308
230/300, train_loss: 6.6590
231/300, train_loss: 5.3162
232/300, train_loss: 0.0131
233/300, train_loss: 3.2949
234/300, train_loss: 4.8915
235/300, train_loss: 0.2490
236/300, train_loss: 6.5301
237/300, train_loss: 2.8388
238/300, train_loss: 7.8190
239/300, train_loss: 1.4604
240/300, train_loss: 4.2703
241/300, train_loss: 3.9553
242/300, train_loss: 1.2026
243/300, train_loss: 1.1606
244/300, train_loss: 0.6377
245/300, train_loss: 7.5062
246/300, train_loss: 5.6394
247/300, train_loss: 6.3916
248/300, train_loss: 4.7484
249/300, train_loss: 4.3087
250/300, train_loss: 4.0787
251/300, train_loss: 5.7467
252/300, train_loss: 4.1468
253/300, train_loss: 2.9128
254/300, train_loss: 3.9295
255/300, train_loss: 9.2353
256/300, train_loss: 5.8877
257/300, train_loss: 4.7344
258/300, train_loss: 2.6041
259/300, train_loss: 6.8599
260/300, train_loss: 2.5426
261/300, train_loss: 3.2158
262/300, train_loss: 2.3084
263/300, train_loss: 1.6928
264/300, train_loss: 1.4420
265/300, train_loss: 4.2242
266/300, train_loss: 0.2204
267/300, train_loss: 2.9310
268/300, train_loss: 4.1112
269/300, train_loss: 0.4634
270/300, train_loss: 3.6117
271/300, train_loss: 4.0554
272/300, train_loss: 3.9300
273/300, train_loss: 3.4463
274/300, train_loss: 1.3255
275/300, train_loss: 1.6774
276/300, train_loss: 3.3683
277/300, train_loss: 5.1274
278/300, train_loss: 2.6176
279/300, train_loss: 1.5735
280/300, train_loss: 2.2163
281/300, train_loss: 2.7843
282/300, train_loss: 6.4840
283/300, train_loss: 0.1230
284/300, train_loss: 2.9713
285/300, train_loss: 8.9592
286/300, train_loss: 3.3363
287/300, train_loss: 1.2253
288/300, train_loss: 3.5402
289/300, train_loss: 1.8905
290/300, train_loss: 7.2648
291/300, train_loss: 1.2573
292/300, train_loss: 5.0237
293/300, train_loss: 1.6964
294/300, train_loss: 4.1406
295/300, train_loss: 1.0852
296/300, train_loss: 1.3424
297/300, train_loss: 2.6253
298/300, train_loss: 2.1988
299/300, train_loss: 2.0063
300/300, train_loss: 7.7543
epoch 1 average loss: 4.0206
----------
epoch 2/150
1/300, train_loss: 2.7225
2/300, train_loss: 4.7777
3/300, train_loss: 2.2000
4/300, train_loss: 4.5911
5/300, train_loss: 6.1597
6/300, train_loss: 2.4293
7/300, train_loss: 4.5922
8/300, train_loss: 2.4753
9/300, train_loss: 4.2890
10/300, train_loss: 2.2840
11/300, train_loss: 8.9412
12/300, train_loss: 8.5174
13/300, train_loss: 7.5253
14/300, train_loss: 3.3283
15/300, train_loss: 0.9788
16/300, train_loss: 8.9472
17/300, train_loss: 4.6040
18/300, train_loss: 1.2643
19/300, train_loss: 3.7967
20/300, train_loss: 0.7506
21/300, train_loss: 1.5605
22/300, train_loss: 0.8400
23/300, train_loss: 4.1553
24/300, train_loss: 3.3601
25/300, train_loss: 5.7083
26/300, train_loss: 2.7520
27/300, train_loss: 1.4918
28/300, train_loss: 1.6170
29/300, train_loss: 3.9621
30/300, train_loss: 5.0098
31/300, train_loss: 3.6706
32/300, train_loss: 5.3089
33/300, train_loss: 8.2492
34/300, train_loss: 5.2887
35/300, train_loss: 0.9229
36/300, train_loss: 0.0937
37/300, train_loss: 1.8937
38/300, train_loss: 2.5254
39/300, train_loss: 2.2050
40/300, train_loss: 4.0651
41/300, train_loss: 6.6208
42/300, train_loss: 2.2123
43/300, train_loss: 5.2178
44/300, train_loss: 3.9763
45/300, train_loss: 2.8978
46/300, train_loss: 3.2976
47/300, train_loss: 2.5600
48/300, train_loss: 8.8555
49/300, train_loss: 4.1474
50/300, train_loss: 3.5753
51/300, train_loss: 4.3626
52/300, train_loss: 7.1414
53/300, train_loss: 4.6639
54/300, train_loss: 1.3588
55/300, train_loss: 0.3830
56/300, train_loss: 2.5571
57/300, train_loss: 0.0060
58/300, train_loss: 5.4004
59/300, train_loss: 4.4445
60/300, train_loss: 4.1484
61/300, train_loss: 4.8916
62/300, train_loss: 2.3580
63/300, train_loss: 1.2950
64/300, train_loss: 1.0304
65/300, train_loss: 7.1595
66/300, train_loss: 3.6131
67/300, train_loss: 5.8968
68/300, train_loss: 4.0457
69/300, train_loss: 1.7997
70/300, train_loss: 1.8104
71/300, train_loss: 1.8308
72/300, train_loss: 6.6245
73/300, train_loss: 3.7807
74/300, train_loss: 5.1038
75/300, train_loss: 2.4528
76/300, train_loss: 5.8459
77/300, train_loss: 2.6092
78/300, train_loss: 1.3478
79/300, train_loss: 0.4111
80/300, train_loss: 1.1143
81/300, train_loss: 6.2366
82/300, train_loss: 0.6728
83/300, train_loss: 6.8972
84/300, train_loss: 1.7623
85/300, train_loss: 7.6248
86/300, train_loss: 0.7534
87/300, train_loss: 3.5730
88/300, train_loss: 3.9749
89/300, train_loss: 2.9248
90/300, train_loss: 6.0798
91/300, train_loss: 3.0155
92/300, train_loss: 2.8871
93/300, train_loss: 3.5381
94/300, train_loss: 5.5534
95/300, train_loss: 1.2431
96/300, train_loss: 2.6933
97/300, train_loss: 1.5044
98/300, train_loss: 8.4282
99/300, train_loss: 8.5612
100/300, train_loss: 3.8176
101/300, train_loss: 6.9215
102/300, train_loss: 3.4087
103/300, train_loss: 7.6020
104/300, train_loss: 1.1393
105/300, train_loss: 9.1040
106/300, train_loss: 3.3032
107/300, train_loss: 3.5073
108/300, train_loss: 2.5461
109/300, train_loss: 0.2007
110/300, train_loss: 5.6803
111/300, train_loss: 6.8080
112/300, train_loss: 3.3067
113/300, train_loss: 2.5614
114/300, train_loss: 1.6446
115/300, train_loss: 3.4542
116/300, train_loss: 7.9422
117/300, train_loss: 1.6284
118/300, train_loss: 7.6386
119/300, train_loss: 3.5121
120/300, train_loss: 0.7243
121/300, train_loss: 0.2327
122/300, train_loss: 5.5234
123/300, train_loss: 4.2342
124/300, train_loss: 5.0870
125/300, train_loss: 2.0359
126/300, train_loss: 1.0369
127/300, train_loss: 4.1490
128/300, train_loss: 1.8824
129/300, train_loss: 7.5385
130/300, train_loss: 2.8633
131/300, train_loss: 6.5380
132/300, train_loss: 3.4982
133/300, train_loss: 5.8208
134/300, train_loss: 7.2972
135/300, train_loss: 5.7469
136/300, train_loss: 1.1698
137/300, train_loss: 0.6629
138/300, train_loss: 2.7571
139/300, train_loss: 6.4364
140/300, train_loss: 2.9985
141/300, train_loss: 3.4203
142/300, train_loss: 3.1496
143/300, train_loss: 4.8174
144/300, train_loss: 1.0543
145/300, train_loss: 7.5776
146/300, train_loss: 1.0776
147/300, train_loss: 1.3869
148/300, train_loss: 6.6402
149/300, train_loss: 0.2033
150/300, train_loss: 4.8247
151/300, train_loss: 5.4025
152/300, train_loss: 4.4861
153/300, train_loss: 2.9324
154/300, train_loss: 0.6104
155/300, train_loss: 4.9973
156/300, train_loss: 3.7580
157/300, train_loss: 2.6292
158/300, train_loss: 3.1207
159/300, train_loss: 9.1009
160/300, train_loss: 3.1376
161/300, train_loss: 2.3544
162/300, train_loss: 6.4867
163/300, train_loss: 2.6754
164/300, train_loss: 6.3612
165/300, train_loss: 1.0804
166/300, train_loss: 5.2336
167/300, train_loss: 5.6470
168/300, train_loss: 1.6513
169/300, train_loss: 2.2236
170/300, train_loss: 6.3022
171/300, train_loss: 1.5089
172/300, train_loss: 1.7092
173/300, train_loss: 1.1455
174/300, train_loss: 1.6105
175/300, train_loss: 2.0861
176/300, train_loss: 1.2620
177/300, train_loss: 1.4566
178/300, train_loss: 3.6142
179/300, train_loss: 0.6411
180/300, train_loss: 1.7085
181/300, train_loss: 1.2099
182/300, train_loss: 4.2738
183/300, train_loss: 2.6156
184/300, train_loss: 7.1964
185/300, train_loss: 0.2480
186/300, train_loss: 2.6691
187/300, train_loss: 9.0547
188/300, train_loss: 8.4716
189/300, train_loss: 2.3489
190/300, train_loss: 2.9319
191/300, train_loss: 5.7738
192/300, train_loss: 5.3837
193/300, train_loss: 7.7047
194/300, train_loss: 5.3916
195/300, train_loss: 8.9693
196/300, train_loss: 3.9832
197/300, train_loss: 0.9599
198/300, train_loss: 0.4201
199/300, train_loss: 3.4722
200/300, train_loss: 10.6520
201/300, train_loss: 3.7313
202/300, train_loss: 2.8014
203/300, train_loss: 1.5153
204/300, train_loss: 3.5859
205/300, train_loss: 6.2925
206/300, train_loss: 5.1480
207/300, train_loss: 5.7675
208/300, train_loss: 0.7939
209/300, train_loss: 3.9160
210/300, train_loss: 3.8431
211/300, train_loss: 8.1729
212/300, train_loss: 5.2480
213/300, train_loss: 5.5725
214/300, train_loss: 1.8697
215/300, train_loss: 2.7254
216/300, train_loss: 1.4881
217/300, train_loss: 6.8948
218/300, train_loss: 6.2525
219/300, train_loss: 4.4595
220/300, train_loss: 1.5998
221/300, train_loss: 5.5160
222/300, train_loss: 6.0145
223/300, train_loss: 3.6852
224/300, train_loss: 8.4699
225/300, train_loss: 4.0832
226/300, train_loss: 1.9479
227/300, train_loss: 4.9612
228/300, train_loss: 3.0364
229/300, train_loss: 8.2347
230/300, train_loss: 4.3136
231/300, train_loss: 5.5128
232/300, train_loss: 7.8931
233/300, train_loss: 2.9334
234/300, train_loss: 7.6010
235/300, train_loss: 2.1331
236/300, train_loss: 2.6143
237/300, train_loss: 5.8705
238/300, train_loss: 0.8097
239/300, train_loss: 6.3707
240/300, train_loss: 0.2058
241/300, train_loss: 6.9023
242/300, train_loss: 4.3899
243/300, train_loss: 2.7060
244/300, train_loss: 4.4356
245/300, train_loss: 1.9308
246/300, train_loss: 3.7320
247/300, train_loss: 4.7193
248/300, train_loss: 0.1133
249/300, train_loss: 6.3738
250/300, train_loss: 2.0696
251/300, train_loss: 5.4784
252/300, train_loss: 1.3862
253/300, train_loss: 3.6507
254/300, train_loss: 2.3202
255/300, train_loss: 0.1041
256/300, train_loss: 3.4884
257/300, train_loss: 1.5226
258/300, train_loss: 4.1532
259/300, train_loss: 5.4405
260/300, train_loss: 5.7701
261/300, train_loss: 6.3083
262/300, train_loss: 6.7733
263/300, train_loss: 4.7640
264/300, train_loss: 1.9782
265/300, train_loss: 2.3408
266/300, train_loss: 2.0244
267/300, train_loss: 3.4069
268/300, train_loss: 0.8123
269/300, train_loss: 4.8807
270/300, train_loss: 8.2206
271/300, train_loss: 8.9148
272/300, train_loss: 0.9158
273/300, train_loss: 1.3915
274/300, train_loss: 6.1893
275/300, train_loss: 3.5335
276/300, train_loss: 2.5593
277/300, train_loss: 2.4014
278/300, train_loss: 5.0122
279/300, train_loss: 3.5935
280/300, train_loss: 2.9762
281/300, train_loss: 1.0645
282/300, train_loss: 3.4724
283/300, train_loss: 2.2689
284/300, train_loss: 3.0812
285/300, train_loss: 2.0695
286/300, train_loss: 3.8001
287/300, train_loss: 4.7329
288/300, train_loss: 3.0812
289/300, train_loss: 0.0814
290/300, train_loss: 7.2823
291/300, train_loss: 2.6503
292/300, train_loss: 7.3249
293/300, train_loss: 7.4053
294/300, train_loss: 2.0115
295/300, train_loss: 0.0346
296/300, train_loss: 3.7188
297/300, train_loss: 1.7394
298/300, train_loss: 7.9737
299/300, train_loss: 5.6007
300/300, train_loss: 3.7643
epoch 2 average loss: 3.8538
positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
saved new best metric model = /HippoDense/EfficientNet_04/EfficientNet_04_20220607_012913.pickle
Current epoch: 2 current accuracy: 0.0469
Best accuracy: 0.0469 at epoch 2
----------
epoch 3/150
1/300, train_loss: 8.1427
2/300, train_loss: 4.9983
3/300, train_loss: 3.9716
4/300, train_loss: 8.2222
5/300, train_loss: 7.7190
6/300, train_loss: 9.0340
7/300, train_loss: 2.5933
8/300, train_loss: 2.4024
9/300, train_loss: 8.0016
10/300, train_loss: 4.5222
11/300, train_loss: 4.0070
12/300, train_loss: 2.2484
13/300, train_loss: 0.8554
14/300, train_loss: 3.0014
15/300, train_loss: 0.8351
16/300, train_loss: 5.7832
17/300, train_loss: 2.1250
18/300, train_loss: 3.2358
19/300, train_loss: 2.0252
20/300, train_loss: 3.1193
21/300, train_loss: 6.7036
22/300, train_loss: 1.4387
23/300, train_loss: 0.4315
24/300, train_loss: 5.8094
25/300, train_loss: 5.3148
26/300, train_loss: 1.8241
27/300, train_loss: 0.2530
28/300, train_loss: 5.5512
29/300, train_loss: 2.7929
30/300, train_loss: 1.9221
31/300, train_loss: 5.5590
32/300, train_loss: 6.6180
33/300, train_loss: 5.4813
34/300, train_loss: 6.2485
35/300, train_loss: 4.9167
36/300, train_loss: 1.6901
37/300, train_loss: 0.9178
38/300, train_loss: 6.2393
39/300, train_loss: 0.5638
40/300, train_loss: 2.9244
41/300, train_loss: 6.1535
42/300, train_loss: 8.9119
43/300, train_loss: 4.3095
44/300, train_loss: 4.8663
45/300, train_loss: 2.5439
46/300, train_loss: 6.0319
47/300, train_loss: 2.1802
48/300, train_loss: 5.4719
49/300, train_loss: 1.8351
50/300, train_loss: 3.8206
51/300, train_loss: 7.8241
52/300, train_loss: 2.6690
53/300, train_loss: 5.9968
54/300, train_loss: 3.4776
55/300, train_loss: 1.3053
56/300, train_loss: 0.2372
57/300, train_loss: 2.0266
58/300, train_loss: 8.8339
59/300, train_loss: 4.6166
60/300, train_loss: 6.1654
61/300, train_loss: 9.6235
62/300, train_loss: 3.3249
63/300, train_loss: 4.9015
64/300, train_loss: 0.1271
65/300, train_loss: 4.0270
66/300, train_loss: 0.8831
67/300, train_loss: 1.9618
68/300, train_loss: 6.4490
69/300, train_loss: 0.8112
70/300, train_loss: 1.2483
71/300, train_loss: 3.0151
72/300, train_loss: 4.9896
73/300, train_loss: 5.8915
74/300, train_loss: 1.4953
75/300, train_loss: 0.0727
76/300, train_loss: 2.3274
77/300, train_loss: 2.1628
78/300, train_loss: 1.7142
79/300, train_loss: 0.0993
80/300, train_loss: 8.5742
81/300, train_loss: 2.1212
82/300, train_loss: 1.8494
83/300, train_loss: 4.1576
84/300, train_loss: 1.1185
85/300, train_loss: 0.1258
86/300, train_loss: 5.8020
87/300, train_loss: 1.7117
88/300, train_loss: 3.2437
89/300, train_loss: 3.8607
90/300, train_loss: 6.2107
91/300, train_loss: 6.7501
92/300, train_loss: 1.0405
93/300, train_loss: 4.6770
94/300, train_loss: 2.3159
95/300, train_loss: 3.0375
96/300, train_loss: 3.8181
97/300, train_loss: 1.6486
98/300, train_loss: 5.5604
99/300, train_loss: 1.7326
100/300, train_loss: 5.4420
101/300, train_loss: 3.1997
102/300, train_loss: 1.6225
103/300, train_loss: 2.4929
104/300, train_loss: 3.0859
105/300, train_loss: 10.5729
106/300, train_loss: 3.9142
107/300, train_loss: 0.3295
108/300, train_loss: 2.2065
109/300, train_loss: 1.9037
110/300, train_loss: 6.2681
111/300, train_loss: 3.6990
112/300, train_loss: 4.1606
113/300, train_loss: 6.4584
114/300, train_loss: 2.6985
115/300, train_loss: 4.9606
116/300, train_loss: 3.4873
117/300, train_loss: 8.5591
118/300, train_loss: 0.7516
119/300, train_loss: 7.5225
120/300, train_loss: 0.3960
121/300, train_loss: 4.5507
122/300, train_loss: 3.4253
123/300, train_loss: 6.3409
124/300, train_loss: 0.8584
125/300, train_loss: 4.4705
126/300, train_loss: 1.5990
127/300, train_loss: 2.8437
128/300, train_loss: 2.6393
129/300, train_loss: 2.5023
130/300, train_loss: 3.1670
131/300, train_loss: 4.5576
132/300, train_loss: 3.6161
133/300, train_loss: 4.9110
134/300, train_loss: 4.8725
135/300, train_loss: 2.9607
136/300, train_loss: 2.0765
137/300, train_loss: 1.7105
138/300, train_loss: 5.1838
139/300, train_loss: 3.1576
140/300, train_loss: 10.8949
141/300, train_loss: 5.8809
142/300, train_loss: 3.6792
143/300, train_loss: 0.2778
144/300, train_loss: 2.7376
145/300, train_loss: 1.7520
146/300, train_loss: 3.9162
147/300, train_loss: 0.5784
148/300, train_loss: 2.4289
149/300, train_loss: 2.4216
150/300, train_loss: 5.1437
151/300, train_loss: 2.2446
152/300, train_loss: 6.6485
153/300, train_loss: 4.7126
154/300, train_loss: 1.1232
155/300, train_loss: 1.3836
156/300, train_loss: 2.1503
157/300, train_loss: 5.8693
158/300, train_loss: 0.6324
159/300, train_loss: 7.1735
160/300, train_loss: 3.7085
161/300, train_loss: 3.3409
162/300, train_loss: 4.6971
163/300, train_loss: 7.4540
164/300, train_loss: 4.5622
165/300, train_loss: 2.5309
166/300, train_loss: 2.3490
167/300, train_loss: 0.3521
168/300, train_loss: 0.6753
169/300, train_loss: 9.5775
170/300, train_loss: 7.1848
171/300, train_loss: 6.0660
172/300, train_loss: 6.7883
173/300, train_loss: 3.3797
174/300, train_loss: 2.1307
175/300, train_loss: 0.7799
176/300, train_loss: 3.0514
177/300, train_loss: 4.0779
178/300, train_loss: 2.9536
179/300, train_loss: 9.2526
180/300, train_loss: 2.4837
181/300, train_loss: 3.2194
182/300, train_loss: 1.3890
183/300, train_loss: 4.0737
184/300, train_loss: 2.3210
185/300, train_loss: 4.6434
186/300, train_loss: 6.1307
187/300, train_loss: 0.6957
188/300, train_loss: 5.3052
189/300, train_loss: 4.6657
190/300, train_loss: 7.1698
191/300, train_loss: 3.7549
192/300, train_loss: 0.1796
193/300, train_loss: 4.3124
194/300, train_loss: 4.3086
195/300, train_loss: 5.2121
196/300, train_loss: 7.6278
197/300, train_loss: 3.9675
198/300, train_loss: 1.5426
199/300, train_loss: 8.3240
200/300, train_loss: 1.1495
201/300, train_loss: 8.4435
202/300, train_loss: 0.7094
203/300, train_loss: 6.6623
204/300, train_loss: 3.2436
205/300, train_loss: 5.7917
206/300, train_loss: 2.3660
207/300, train_loss: 5.8745
208/300, train_loss: 6.1894
209/300, train_loss: 1.2644
210/300, train_loss: 0.8146
211/300, train_loss: 4.6816
212/300, train_loss: 6.5940
213/300, train_loss: 3.9233
214/300, train_loss: 4.2063
215/300, train_loss: 3.2935
216/300, train_loss: 1.0823
217/300, train_loss: 1.9464
218/300, train_loss: 2.7028
219/300, train_loss: 2.7910
220/300, train_loss: 1.4166
221/300, train_loss: 7.7781
222/300, train_loss: 0.0520
223/300, train_loss: 2.0744
224/300, train_loss: 7.6471
225/300, train_loss: 3.8221
226/300, train_loss: 2.7027
227/300, train_loss: 8.1963
228/300, train_loss: 1.8492
229/300, train_loss: 1.5058
230/300, train_loss: 2.2950
231/300, train_loss: 6.5213
232/300, train_loss: 2.9716
233/300, train_loss: 6.5001
234/300, train_loss: 3.8859
235/300, train_loss: 6.5427
236/300, train_loss: 8.5558
237/300, train_loss: 3.5822
238/300, train_loss: 5.9380
239/300, train_loss: 7.3679
240/300, train_loss: 5.2030
241/300, train_loss: 1.8634
242/300, train_loss: 8.2378
243/300, train_loss: 4.2971
244/300, train_loss: 6.1204
245/300, train_loss: 6.7446
246/300, train_loss: 4.8994
247/300, train_loss: 3.7438
248/300, train_loss: 1.9534
249/300, train_loss: 0.2709
250/300, train_loss: 1.9271
251/300, train_loss: 2.3690
252/300, train_loss: 1.0079
253/300, train_loss: 3.1302
254/300, train_loss: 2.1407
255/300, train_loss: 6.1405
256/300, train_loss: 3.6854
257/300, train_loss: 0.1532
258/300, train_loss: 1.7240
259/300, train_loss: 4.8999
260/300, train_loss: 3.2022
261/300, train_loss: 8.6850
262/300, train_loss: 4.5188
263/300, train_loss: 4.8869
264/300, train_loss: 6.4799
265/300, train_loss: 4.8680
266/300, train_loss: 6.2120
267/300, train_loss: 5.3866
268/300, train_loss: 0.8917
269/300, train_loss: 3.6035
270/300, train_loss: 6.8589
271/300, train_loss: 2.0653
272/300, train_loss: 4.4161
273/300, train_loss: 4.2254
274/300, train_loss: 6.1317
275/300, train_loss: 5.4141
276/300, train_loss: 0.7086
277/300, train_loss: 2.6375
278/300, train_loss: 1.6939
279/300, train_loss: 5.2610
280/300, train_loss: 0.4541
281/300, train_loss: 1.2708
282/300, train_loss: 6.1876
283/300, train_loss: 4.1289
284/300, train_loss: 3.9496
285/300, train_loss: 3.5293
286/300, train_loss: 4.9125
287/300, train_loss: 1.8171
288/300, train_loss: 2.7850
289/300, train_loss: 2.1352
290/300, train_loss: 3.0146
291/300, train_loss: 4.6943
292/300, train_loss: 6.9903
293/300, train_loss: 6.5329
294/300, train_loss: 5.3004
295/300, train_loss: 2.6992
296/300, train_loss: 1.8411
297/300, train_loss: 8.6991
298/300, train_loss: 1.7229
299/300, train_loss: 4.2744
300/300, train_loss: 2.4903
epoch 3 average loss: 3.8796
----------
epoch 4/150
1/300, train_loss: 1.4099
2/300, train_loss: 4.9212
3/300, train_loss: 0.3288
4/300, train_loss: 1.7726
5/300, train_loss: 1.2483
6/300, train_loss: 5.2063
7/300, train_loss: 6.4717
8/300, train_loss: 6.2784
9/300, train_loss: 1.7257
10/300, train_loss: 5.0494
11/300, train_loss: 1.9012
12/300, train_loss: 6.6498
13/300, train_loss: 2.5204
14/300, train_loss: 0.2845
15/300, train_loss: 1.3491
16/300, train_loss: 6.5016
17/300, train_loss: 6.2918
18/300, train_loss: 2.8791
19/300, train_loss: 3.9600
20/300, train_loss: 1.9911
21/300, train_loss: 3.5994
22/300, train_loss: 5.7272
23/300, train_loss: 1.7020
24/300, train_loss: 5.9091
25/300, train_loss: 5.5662
26/300, train_loss: 5.0029
27/300, train_loss: 3.6029
28/300, train_loss: 2.7928
29/300, train_loss: 2.9734
30/300, train_loss: 8.5838
31/300, train_loss: 5.2011
32/300, train_loss: 6.0878
33/300, train_loss: 1.5125
34/300, train_loss: 0.0596
35/300, train_loss: 0.8237
36/300, train_loss: 3.8072
37/300, train_loss: 5.4531
38/300, train_loss: 7.5659
39/300, train_loss: 5.0591
40/300, train_loss: 2.5945
41/300, train_loss: 5.2675
42/300, train_loss: 2.2971
43/300, train_loss: 2.8978
44/300, train_loss: 9.2734
45/300, train_loss: 4.2831
46/300, train_loss: 4.2294
47/300, train_loss: 0.4779
48/300, train_loss: 3.6170
49/300, train_loss: 1.8526
50/300, train_loss: 0.0061
51/300, train_loss: 6.7204
52/300, train_loss: 1.5829
53/300, train_loss: 7.1813
54/300, train_loss: 0.0485
55/300, train_loss: 3.6273
56/300, train_loss: 6.5404
57/300, train_loss: 4.2970
58/300, train_loss: 2.1048
59/300, train_loss: 3.1679
60/300, train_loss: 3.1344
61/300, train_loss: 1.9988
62/300, train_loss: 5.2489
63/300, train_loss: 1.7857
64/300, train_loss: 3.1664
65/300, train_loss: 3.6615
66/300, train_loss: 6.9051
67/300, train_loss: 6.3456
68/300, train_loss: 7.0019
69/300, train_loss: 3.3468
70/300, train_loss: 3.2666
71/300, train_loss: 4.8510
72/300, train_loss: 1.1753
73/300, train_loss: 1.5038
74/300, train_loss: 1.6780
75/300, train_loss: 6.5763
76/300, train_loss: 3.8836
77/300, train_loss: 0.4136
78/300, train_loss: 8.7965
79/300, train_loss: 3.6710
80/300, train_loss: 5.7943
81/300, train_loss: 4.5952
82/300, train_loss: 5.9480
83/300, train_loss: 6.6559
84/300, train_loss: 2.2292
85/300, train_loss: 1.3061
86/300, train_loss: 4.5829
87/300, train_loss: 3.4155
88/300, train_loss: 3.6619
89/300, train_loss: 6.3063
90/300, train_loss: 1.4404
91/300, train_loss: 2.7093
92/300, train_loss: 4.9766
93/300, train_loss: 1.3175
94/300, train_loss: 4.4800
95/300, train_loss: 5.5785
96/300, train_loss: 2.7888
97/300, train_loss: 7.7441
98/300, train_loss: 5.3647
99/300, train_loss: 3.9977
100/300, train_loss: 2.4622
101/300, train_loss: 4.6687
102/300, train_loss: 4.7621
103/300, train_loss: 2.0295
104/300, train_loss: 2.6010
105/300, train_loss: 2.8072
106/300, train_loss: 2.7255
107/300, train_loss: 1.9946
108/300, train_loss: 1.8437
109/300, train_loss: 1.9525
110/300, train_loss: 4.3200
111/300, train_loss: 3.8666
112/300, train_loss: 0.8410
113/300, train_loss: 5.4317
114/300, train_loss: 7.2623
115/300, train_loss: 7.8496
116/300, train_loss: 1.8937
117/300, train_loss: 6.0526
118/300, train_loss: 2.4337
119/300, train_loss: 0.8176
120/300, train_loss: 10.3608
121/300, train_loss: 3.4934
122/300, train_loss: 3.5789
123/300, train_loss: 3.1063
124/300, train_loss: 0.2508
125/300, train_loss: 4.6673
126/300, train_loss: 1.9102
127/300, train_loss: 5.3817
128/300, train_loss: 6.2721
129/300, train_loss: 4.1473
130/300, train_loss: 8.5873
131/300, train_loss: 2.1758
132/300, train_loss: 1.0539
133/300, train_loss: 0.0851
134/300, train_loss: 8.4762
135/300, train_loss: 1.3896
136/300, train_loss: 6.9268
137/300, train_loss: 0.9961
138/300, train_loss: 4.9780
139/300, train_loss: 7.3220
140/300, train_loss: 1.4782
141/300, train_loss: 0.6374
142/300, train_loss: 5.5978
143/300, train_loss: 1.8545
144/300, train_loss: 0.1822
145/300, train_loss: 7.0367
146/300, train_loss: 1.0528
147/300, train_loss: 0.9838
148/300, train_loss: 1.0912
149/300, train_loss: 2.4160
150/300, train_loss: 3.0103
151/300, train_loss: 1.1119
152/300, train_loss: 5.7916
153/300, train_loss: 8.7449
154/300, train_loss: 0.5244
155/300, train_loss: 1.0674
156/300, train_loss: 5.8395
157/300, train_loss: 2.6453
158/300, train_loss: 2.5722
159/300, train_loss: 5.5924
160/300, train_loss: 2.1253
161/300, train_loss: 6.2440
162/300, train_loss: 6.5197
163/300, train_loss: 4.5027
164/300, train_loss: 2.5483
165/300, train_loss: 3.5502
166/300, train_loss: 4.7518
167/300, train_loss: 4.1937
168/300, train_loss: 0.6803
169/300, train_loss: 8.7325
170/300, train_loss: 1.4542
171/300, train_loss: 6.5967
172/300, train_loss: 4.4522
173/300, train_loss: 1.3337
174/300, train_loss: 1.2402
175/300, train_loss: 3.5099
176/300, train_loss: 4.0223
177/300, train_loss: 0.8637
178/300, train_loss: 1.6622
179/300, train_loss: 3.3149
180/300, train_loss: 1.5493
181/300, train_loss: 6.5944
182/300, train_loss: 6.3667
183/300, train_loss: 5.1925
184/300, train_loss: 0.9024
185/300, train_loss: 7.0482
186/300, train_loss: 5.7864
187/300, train_loss: 3.8851
188/300, train_loss: 5.8686
189/300, train_loss: 2.3373
190/300, train_loss: 1.2141
191/300, train_loss: 8.6377
192/300, train_loss: 2.1934
193/300, train_loss: 3.4050
194/300, train_loss: 3.1151
195/300, train_loss: 3.8320
196/300, train_loss: 4.9804
197/300, train_loss: 5.5161
198/300, train_loss: 4.9451
199/300, train_loss: 3.0760
200/300, train_loss: 8.2543
201/300, train_loss: 5.4969
202/300, train_loss: 7.0619
203/300, train_loss: 3.4427
204/300, train_loss: 5.0020
205/300, train_loss: 3.3061
206/300, train_loss: 7.7164
207/300, train_loss: 0.7608
208/300, train_loss: 3.4178
209/300, train_loss: 1.0485
210/300, train_loss: 7.7498
211/300, train_loss: 7.8741
212/300, train_loss: 6.3606
213/300, train_loss: 4.0548
214/300, train_loss: 3.2141
215/300, train_loss: 6.2749
216/300, train_loss: 6.6226
217/300, train_loss: 1.7068
218/300, train_loss: 4.7172
219/300, train_loss: 4.8367
220/300, train_loss: 9.7123
221/300, train_loss: 3.3848
222/300, train_loss: 1.7232
223/300, train_loss: 0.3777
224/300, train_loss: 0.0207
225/300, train_loss: 4.5520
226/300, train_loss: 2.0336
227/300, train_loss: 3.3446
228/300, train_loss: 0.7099
229/300, train_loss: 0.6960
230/300, train_loss: 4.4697
231/300, train_loss: 3.4455
232/300, train_loss: 1.9074
233/300, train_loss: 4.8490
234/300, train_loss: 2.3793
235/300, train_loss: 1.4455
236/300, train_loss: 2.9140
237/300, train_loss: 6.4795
238/300, train_loss: 7.1324
239/300, train_loss: 4.3403
240/300, train_loss: 6.6840
241/300, train_loss: 4.6488
242/300, train_loss: 1.4655
243/300, train_loss: 1.0292
244/300, train_loss: 3.8831
245/300, train_loss: 4.1606
246/300, train_loss: 6.8262
247/300, train_loss: 8.0356
248/300, train_loss: 4.4822
249/300, train_loss: 1.5384
250/300, train_loss: 1.2242
251/300, train_loss: 3.1070
252/300, train_loss: 6.9389
253/300, train_loss: 3.1979
254/300, train_loss: 4.8575
255/300, train_loss: 7.9239
256/300, train_loss: 1.9794
257/300, train_loss: 7.1022
258/300, train_loss: 1.3222
259/300, train_loss: 5.1664
260/300, train_loss: 1.4450
261/300, train_loss: 2.9762
262/300, train_loss: 2.4794
263/300, train_loss: 1.4632
264/300, train_loss: 1.5909
265/300, train_loss: 10.1316
266/300, train_loss: 7.0207
267/300, train_loss: 4.8154
268/300, train_loss: 6.7286
269/300, train_loss: 5.8726
270/300, train_loss: 4.5319
271/300, train_loss: 0.0694
272/300, train_loss: 3.6566
273/300, train_loss: 3.6594
274/300, train_loss: 5.4186
275/300, train_loss: 5.8282
276/300, train_loss: 5.8452
277/300, train_loss: 6.9145
278/300, train_loss: 4.2661
279/300, train_loss: 3.4347
280/300, train_loss: 4.3616
281/300, train_loss: 7.4433
282/300, train_loss: 3.9491
283/300, train_loss: 3.7165
284/300, train_loss: 1.8095
285/300, train_loss: 1.4645
286/300, train_loss: 3.9214
287/300, train_loss: 2.8289
288/300, train_loss: 1.3110
289/300, train_loss: 3.4007
290/300, train_loss: 0.5387
291/300, train_loss: 9.1547
292/300, train_loss: 6.8994
293/300, train_loss: 6.1921
294/300, train_loss: 0.9694
295/300, train_loss: 1.5842
296/300, train_loss: 3.2485
297/300, train_loss: 2.6561
298/300, train_loss: 7.9493
299/300, train_loss: 3.0572
300/300, train_loss: 1.4752
epoch 4 average loss: 3.9113
Current epoch: 4 current accuracy: 0.0469
Best accuracy: 0.0469 at epoch 2
----------
epoch 5/150
1/300, train_loss: 1.8981
2/300, train_loss: 5.8703
3/300, train_loss: 0.8849
4/300, train_loss: 3.7979
5/300, train_loss: 2.8652
6/300, train_loss: 3.0585
7/300, train_loss: 4.0064
8/300, train_loss: 8.7144
9/300, train_loss: 0.4539
10/300, train_loss: 3.9830
11/300, train_loss: 6.7164
12/300, train_loss: 2.7514
13/300, train_loss: 3.8925
14/300, train_loss: 2.3671
15/300, train_loss: 10.1179
16/300, train_loss: 4.6867
17/300, train_loss: 2.1109
18/300, train_loss: 8.5251
19/300, train_loss: 4.7971
20/300, train_loss: 7.8623
21/300, train_loss: 0.1031
22/300, train_loss: 0.9534
23/300, train_loss: 8.7263
24/300, train_loss: 7.1602
25/300, train_loss: 5.3416
26/300, train_loss: 2.1530
27/300, train_loss: 8.0132
28/300, train_loss: 5.0436
29/300, train_loss: 1.4560
30/300, train_loss: 0.9657
31/300, train_loss: 4.2808
32/300, train_loss: 2.3248
33/300, train_loss: 8.0738
34/300, train_loss: 2.6951
35/300, train_loss: 5.5006
36/300, train_loss: 1.1682
37/300, train_loss: 2.6434
38/300, train_loss: 2.8348
39/300, train_loss: 2.8297
40/300, train_loss: 2.8468
41/300, train_loss: 4.3266
42/300, train_loss: 7.3881
43/300, train_loss: 3.2908
44/300, train_loss: 5.8953
45/300, train_loss: 4.4119
46/300, train_loss: 2.4653
47/300, train_loss: 1.4814
48/300, train_loss: 3.1590
49/300, train_loss: 1.3176
50/300, train_loss: 8.0883
51/300, train_loss: 0.4626
52/300, train_loss: 8.8687
53/300, train_loss: 4.3919
54/300, train_loss: 6.4669
55/300, train_loss: 7.6405
56/300, train_loss: 3.4293
57/300, train_loss: 1.6129
58/300, train_loss: 2.6271
59/300, train_loss: 0.4310
60/300, train_loss: 4.5782
61/300, train_loss: 1.8225
62/300, train_loss: 1.2939
63/300, train_loss: 0.6232
64/300, train_loss: 3.8511
65/300, train_loss: 6.2176
66/300, train_loss: 2.7897
67/300, train_loss: 4.9261
68/300, train_loss: 2.1097
69/300, train_loss: 3.7284
70/300, train_loss: 4.1778
71/300, train_loss: 1.1302
72/300, train_loss: 3.8184
73/300, train_loss: 2.0947
74/300, train_loss: 3.2419
75/300, train_loss: 3.9157
76/300, train_loss: 2.1114
77/300, train_loss: 1.7570
78/300, train_loss: 3.2121
79/300, train_loss: 1.5196
80/300, train_loss: 3.2420
81/300, train_loss: 10.1818
82/300, train_loss: 4.5883
83/300, train_loss: 0.4120
84/300, train_loss: 1.4967
85/300, train_loss: 3.4012
86/300, train_loss: 0.4844
87/300, train_loss: 4.7264
88/300, train_loss: 0.4929
89/300, train_loss: 7.5103
90/300, train_loss: 6.4493
91/300, train_loss: 4.1990
92/300, train_loss: 1.2634
93/300, train_loss: 6.5366
94/300, train_loss: 6.6221
95/300, train_loss: 4.2450
96/300, train_loss: 2.9821
97/300, train_loss: 5.4133
98/300, train_loss: 3.3819
99/300, train_loss: 5.1598
100/300, train_loss: 7.9327
101/300, train_loss: 3.6555
102/300, train_loss: 8.9767
103/300, train_loss: 9.1384
104/300, train_loss: 7.7365
105/300, train_loss: 5.8692
106/300, train_loss: 2.3662
107/300, train_loss: 3.9943
108/300, train_loss: 4.2684
109/300, train_loss: 2.3763
110/300, train_loss: 7.4629
111/300, train_loss: 1.3934
112/300, train_loss: 1.6382
113/300, train_loss: 7.6870
114/300, train_loss: 0.4171
115/300, train_loss: 1.1044
116/300, train_loss: 4.9063
117/300, train_loss: 10.1842
118/300, train_loss: 1.9969
119/300, train_loss: 3.4425
120/300, train_loss: 4.5930
121/300, train_loss: 6.7777
122/300, train_loss: 8.4776
123/300, train_loss: 4.7081
124/300, train_loss: 0.3649
125/300, train_loss: 7.9931
126/300, train_loss: 1.3682
127/300, train_loss: 6.5132
128/300, train_loss: 4.3856
129/300, train_loss: 8.6757
130/300, train_loss: 7.3102
131/300, train_loss: 6.7072
132/300, train_loss: 4.1807
133/300, train_loss: 2.3105
134/300, train_loss: 1.3698
135/300, train_loss: 2.5137
136/300, train_loss: 0.1151
137/300, train_loss: 0.5859
138/300, train_loss: 3.3622
139/300, train_loss: 1.9278
140/300, train_loss: 4.3032
141/300, train_loss: 5.4231
142/300, train_loss: 4.4008
143/300, train_loss: 6.1427
144/300, train_loss: 7.9404
145/300, train_loss: 7.9963
146/300, train_loss: 3.6405
147/300, train_loss: 2.6858
148/300, train_loss: 7.8678
149/300, train_loss: 0.2689
150/300, train_loss: 8.2134
151/300, train_loss: 5.2495
152/300, train_loss: 4.8134
153/300, train_loss: 7.3125
154/300, train_loss: 5.6349
155/300, train_loss: 0.2920
156/300, train_loss: 5.2387
157/300, train_loss: 4.5808
158/300, train_loss: 6.8504
159/300, train_loss: 3.6891
160/300, train_loss: 2.1979
161/300, train_loss: 5.1403
162/300, train_loss: 0.2679
163/300, train_loss: 5.8001
164/300, train_loss: 1.8086
165/300, train_loss: 0.1336
166/300, train_loss: 3.1255
167/300, train_loss: 2.3947
168/300, train_loss: 5.2272
169/300, train_loss: 8.6743
170/300, train_loss: 5.9910
171/300, train_loss: 1.0782
172/300, train_loss: 11.5671
173/300, train_loss: 3.0638
174/300, train_loss: 2.1945
175/300, train_loss: 6.4201
176/300, train_loss: 6.8593
177/300, train_loss: 1.7559
178/300, train_loss: 1.9316
179/300, train_loss: 1.8418
180/300, train_loss: 4.5858
181/300, train_loss: 3.6085
182/300, train_loss: 1.1275
183/300, train_loss: 1.9591
184/300, train_loss: 0.8853
185/300, train_loss: 3.7309
186/300, train_loss: 2.7389
187/300, train_loss: 4.3303
188/300, train_loss: 0.6625
189/300, train_loss: 3.5197
190/300, train_loss: 3.7285
191/300, train_loss: 4.2004
192/300, train_loss: 4.5606
193/300, train_loss: 2.5406
194/300, train_loss: 1.7033
195/300, train_loss: 3.9534
196/300, train_loss: 0.0699
197/300, train_loss: 4.3464
198/300, train_loss: 5.3376
199/300, train_loss: 1.2585
200/300, train_loss: 2.6926
201/300, train_loss: 1.2038
202/300, train_loss: 2.5904
203/300, train_loss: 1.4190
204/300, train_loss: 2.9716
205/300, train_loss: 1.0873
206/300, train_loss: 7.4615
207/300, train_loss: 2.7958
208/300, train_loss: 2.0088
209/300, train_loss: 4.9686
210/300, train_loss: 5.0905
211/300, train_loss: 5.1072
212/300, train_loss: 8.9282
213/300, train_loss: 9.2280
214/300, train_loss: 2.8406
215/300, train_loss: 2.0250
216/300, train_loss: 3.4983
217/300, train_loss: 6.5789
218/300, train_loss: 2.8560
219/300, train_loss: 1.9426
220/300, train_loss: 5.2354
221/300, train_loss: 6.5654
222/300, train_loss: 4.4325
223/300, train_loss: 4.0397
224/300, train_loss: 2.2059
225/300, train_loss: 3.0627
226/300, train_loss: 1.0746
227/300, train_loss: 5.1728
228/300, train_loss: 1.7779
229/300, train_loss: 5.8943
230/300, train_loss: 8.2729
231/300, train_loss: 2.9866
232/300, train_loss: 6.4222
233/300, train_loss: 3.8215
234/300, train_loss: 3.7025
235/300, train_loss: 6.4430
236/300, train_loss: 2.6941
237/300, train_loss: 4.8558
238/300, train_loss: 0.3475
239/300, train_loss: 0.9878
240/300, train_loss: 3.1839
241/300, train_loss: 1.5602
242/300, train_loss: 2.1849
243/300, train_loss: 3.8279
244/300, train_loss: 3.4764
245/300, train_loss: 8.1569
246/300, train_loss: 8.7743
247/300, train_loss: 1.0933
248/300, train_loss: 1.1442
249/300, train_loss: 1.3427
250/300, train_loss: 4.1059
251/300, train_loss: 7.5279
252/300, train_loss: 1.8340
253/300, train_loss: 8.8402
254/300, train_loss: 2.3262
255/300, train_loss: 2.3186
256/300, train_loss: 6.8872
257/300, train_loss: 4.5758
258/300, train_loss: 0.4434
259/300, train_loss: 1.8855
260/300, train_loss: 3.0095
261/300, train_loss: 0.4850
262/300, train_loss: 6.9887
263/300, train_loss: 4.1932
264/300, train_loss: 5.6659
265/300, train_loss: 1.5952
266/300, train_loss: 0.9500
267/300, train_loss: 1.6203
268/300, train_loss: 7.3891
269/300, train_loss: 2.6242
270/300, train_loss: 2.2287
271/300, train_loss: 6.9947
272/300, train_loss: 1.3862
273/300, train_loss: 0.7600
274/300, train_loss: 2.1145
275/300, train_loss: 4.0312
276/300, train_loss: 2.9624
277/300, train_loss: 3.6784
278/300, train_loss: 4.3892
279/300, train_loss: 1.2785
280/300, train_loss: 2.7144
281/300, train_loss: 6.0949
282/300, train_loss: 2.5373
283/300, train_loss: 4.4989
284/300, train_loss: 0.1145
285/300, train_loss: 4.5860
286/300, train_loss: 2.4496
287/300, train_loss: 4.3976
288/300, train_loss: 4.4943
289/300, train_loss: 3.4132
290/300, train_loss: 1.0800
291/300, train_loss: 2.9180
292/300, train_loss: 6.9739
293/300, train_loss: 4.0869
294/300, train_loss: 2.8111
295/300, train_loss: 4.0337
296/300, train_loss: 1.5859
297/300, train_loss: 0.9932
298/300, train_loss: 5.7619
299/300, train_loss: 4.4489
300/300, train_loss: 6.0483
epoch 5 average loss: 3.9225
----------
epoch 6/150
1/300, train_loss: 9.7741
2/300, train_loss: 2.1724
3/300, train_loss: 1.6728
4/300, train_loss: 0.8919
5/300, train_loss: 3.2165
6/300, train_loss: 2.9192
7/300, train_loss: 1.0620
8/300, train_loss: 0.0467
9/300, train_loss: 3.6918
10/300, train_loss: 4.9699
11/300, train_loss: 3.5594
12/300, train_loss: 0.6145
13/300, train_loss: 4.9841
14/300, train_loss: 6.9079
15/300, train_loss: 5.6931
16/300, train_loss: 0.4497
17/300, train_loss: 6.0549
18/300, train_loss: 6.4884
19/300, train_loss: 4.8241
20/300, train_loss: 4.2598
21/300, train_loss: 6.9642
22/300, train_loss: 6.3948
23/300, train_loss: 3.8380
24/300, train_loss: 3.8345
25/300, train_loss: 9.0762
26/300, train_loss: 2.9859
27/300, train_loss: 3.0590
28/300, train_loss: 4.6227
29/300, train_loss: 1.1475
30/300, train_loss: 4.2826
31/300, train_loss: 7.9873
32/300, train_loss: 0.7898
33/300, train_loss: 6.2954
34/300, train_loss: 2.7720
35/300, train_loss: 1.2826
36/300, train_loss: 5.9271
37/300, train_loss: 3.8971
38/300, train_loss: 2.2776
39/300, train_loss: 1.7753
40/300, train_loss: 6.0315
41/300, train_loss: 1.2718
42/300, train_loss: 2.5809
43/300, train_loss: 1.8184
44/300, train_loss: 5.8166
45/300, train_loss: 5.4988
46/300, train_loss: 2.2153
47/300, train_loss: 5.8015
48/300, train_loss: 1.2300
49/300, train_loss: 0.1492
50/300, train_loss: 2.6919
51/300, train_loss: 3.2160
52/300, train_loss: 6.7149
53/300, train_loss: 1.7238
54/300, train_loss: 2.1690
55/300, train_loss: 7.3159
56/300, train_loss: 2.1594
57/300, train_loss: 2.9973
58/300, train_loss: 4.3205
59/300, train_loss: 1.2493
60/300, train_loss: 3.7733
61/300, train_loss: 3.9188
62/300, train_loss: 3.2464
63/300, train_loss: 2.8680
64/300, train_loss: 5.8322
65/300, train_loss: 7.6258
66/300, train_loss: 2.3064
67/300, train_loss: 8.2876
68/300, train_loss: 9.4598
69/300, train_loss: 3.7211
70/300, train_loss: 7.2816
71/300, train_loss: 1.0797
72/300, train_loss: 2.8885
73/300, train_loss: 1.8447
74/300, train_loss: 1.5050
75/300, train_loss: 3.3045
76/300, train_loss: 4.2794
77/300, train_loss: 5.1745
78/300, train_loss: 0.5062
79/300, train_loss: 3.4998
80/300, train_loss: 5.1260
81/300, train_loss: 7.4033
82/300, train_loss: 2.1976
83/300, train_loss: 6.9650
84/300, train_loss: 0.9694
85/300, train_loss: 5.4228
86/300, train_loss: 2.9731
87/300, train_loss: 1.3274
88/300, train_loss: 4.6213
89/300, train_loss: 4.5303
90/300, train_loss: 3.9925
91/300, train_loss: 0.5049
92/300, train_loss: 4.9776
93/300, train_loss: 3.3660
94/300, train_loss: 4.6458
95/300, train_loss: 5.0534
96/300, train_loss: 2.9380
97/300, train_loss: 1.9268
98/300, train_loss: 1.7135
99/300, train_loss: 3.1252
100/300, train_loss: 5.6839
101/300, train_loss: 1.4869
102/300, train_loss: 7.1091
103/300, train_loss: 4.5010
104/300, train_loss: 3.3791
105/300, train_loss: 3.1585
106/300, train_loss: 4.7031
107/300, train_loss: 0.0808
108/300, train_loss: 4.5614
109/300, train_loss: 3.9180
110/300, train_loss: 6.7459
111/300, train_loss: 1.6189
112/300, train_loss: 6.2201
113/300, train_loss: 0.5412
114/300, train_loss: 1.5617
115/300, train_loss: 8.3617
116/300, train_loss: 1.0314
117/300, train_loss: 4.3557
118/300, train_loss: 3.4586
119/300, train_loss: 2.5118
120/300, train_loss: 4.8864
121/300, train_loss: 3.5602
122/300, train_loss: 8.4533
123/300, train_loss: 1.8535
124/300, train_loss: 3.4682
125/300, train_loss: 1.1094
126/300, train_loss: 6.2469
127/300, train_loss: 8.3541
128/300, train_loss: 1.8443
129/300, train_loss: 6.2321
130/300, train_loss: 1.9356
131/300, train_loss: 6.4733
132/300, train_loss: 1.7860
133/300, train_loss: 5.8529
134/300, train_loss: 7.1154
135/300, train_loss: 6.5883
136/300, train_loss: 6.4990
137/300, train_loss: 6.3195
138/300, train_loss: 4.9311
139/300, train_loss: 3.8467
140/300, train_loss: 3.7960
141/300, train_loss: 5.7768
142/300, train_loss: 1.6709
143/300, train_loss: 2.1622
144/300, train_loss: 6.6197
145/300, train_loss: 0.1875
146/300, train_loss: 2.5040
147/300, train_loss: 5.6815
148/300, train_loss: 0.1582
149/300, train_loss: 3.9773
150/300, train_loss: 3.9035
151/300, train_loss: 5.4956
152/300, train_loss: 6.7823
153/300, train_loss: 5.8061
154/300, train_loss: 1.3210
155/300, train_loss: 2.5355
156/300, train_loss: 1.8836
157/300, train_loss: 1.4536
158/300, train_loss: 0.6935
159/300, train_loss: 6.5369
160/300, train_loss: 2.0550
161/300, train_loss: 1.2664
162/300, train_loss: 3.1284
163/300, train_loss: 4.9378
164/300, train_loss: 3.6934
165/300, train_loss: 3.2178
166/300, train_loss: 1.8252
167/300, train_loss: 1.6946
168/300, train_loss: 2.7948
169/300, train_loss: 4.5940
170/300, train_loss: 7.1029
171/300, train_loss: 7.1356
172/300, train_loss: 2.2428
173/300, train_loss: 1.5508
174/300, train_loss: 4.3766
175/300, train_loss: 3.2423
176/300, train_loss: 2.4056
177/300, train_loss: 5.2220
178/300, train_loss: 5.0267
179/300, train_loss: 2.0301
180/300, train_loss: 0.4186
181/300, train_loss: 8.5151
182/300, train_loss: 0.6777
183/300, train_loss: 7.8700
184/300, train_loss: 4.2841
185/300, train_loss: 3.6634
186/300, train_loss: 5.9618
187/300, train_loss: 3.5625
188/300, train_loss: 0.8485
189/300, train_loss: 7.7571
190/300, train_loss: 4.4782
191/300, train_loss: 8.4246
192/300, train_loss: 1.2140
193/300, train_loss: 7.6955
194/300, train_loss: 4.6763
195/300, train_loss: 1.3427
196/300, train_loss: 3.9380
197/300, train_loss: 4.4579
198/300, train_loss: 2.9822
199/300, train_loss: 3.2666
200/300, train_loss: 4.5019
201/300, train_loss: 7.1461
202/300, train_loss: 6.9458
203/300, train_loss: 7.5647
204/300, train_loss: 1.3829
205/300, train_loss: 2.0919
206/300, train_loss: 1.2849
207/300, train_loss: 6.0166
208/300, train_loss: 2.1776
209/300, train_loss: 3.7124
210/300, train_loss: 7.8741
211/300, train_loss: 0.0797
212/300, train_loss: 4.5484
213/300, train_loss: 6.9053
214/300, train_loss: 3.1370
215/300, train_loss: 3.5637
216/300, train_loss: 1.9142
217/300, train_loss: 0.8453
218/300, train_loss: 0.7346
219/300, train_loss: 5.9617
220/300, train_loss: 8.0572
221/300, train_loss: 4.1050
222/300, train_loss: 0.8119
223/300, train_loss: 5.7853
224/300, train_loss: 1.6707
225/300, train_loss: 3.7835
226/300, train_loss: 0.9207
227/300, train_loss: 3.1821
228/300, train_loss: 5.8727
229/300, train_loss: 6.7751
230/300, train_loss: 1.3737
231/300, train_loss: 3.9859
232/300, train_loss: 0.8075
233/300, train_loss: 6.3377
234/300, train_loss: 1.8163
235/300, train_loss: 4.2437
236/300, train_loss: 7.2557
237/300, train_loss: 5.7257
238/300, train_loss: 0.8767
239/300, train_loss: 1.2782
240/300, train_loss: 2.0336
241/300, train_loss: 5.9350
242/300, train_loss: 0.6611
243/300, train_loss: 4.0097
244/300, train_loss: 6.3757
245/300, train_loss: 2.1421
246/300, train_loss: 0.9027
247/300, train_loss: 2.8130
248/300, train_loss: 0.4458
249/300, train_loss: 1.8668
250/300, train_loss: 5.1735
251/300, train_loss: 3.9445
252/300, train_loss: 1.0047
253/300, train_loss: 2.6270
254/300, train_loss: 1.7985
255/300, train_loss: 7.5942
256/300, train_loss: 3.7757
257/300, train_loss: 1.0563
258/300, train_loss: 3.6884
259/300, train_loss: 2.1796
260/300, train_loss: 5.9777
261/300, train_loss: 2.9084
262/300, train_loss: 1.5352
263/300, train_loss: 3.2465
264/300, train_loss: 5.1185
265/300, train_loss: 5.7611
266/300, train_loss: 6.9921
267/300, train_loss: 0.0078
268/300, train_loss: 7.7307
269/300, train_loss: 5.3122
270/300, train_loss: 7.6930
271/300, train_loss: 1.6599
272/300, train_loss: 7.5859
273/300, train_loss: 2.9607
274/300, train_loss: 4.9952
275/300, train_loss: 1.4839
276/300, train_loss: 3.3453
277/300, train_loss: 1.1389
278/300, train_loss: 6.7700
279/300, train_loss: 3.7356
280/300, train_loss: 6.0209
281/300, train_loss: 9.1878
282/300, train_loss: 5.1734
283/300, train_loss: 0.9271
284/300, train_loss: 3.5434
285/300, train_loss: 10.1884
286/300, train_loss: 5.6379
287/300, train_loss: 1.0629
288/300, train_loss: 5.8559
289/300, train_loss: 8.8380
290/300, train_loss: 0.6041
291/300, train_loss: 7.2307
292/300, train_loss: 3.1365
293/300, train_loss: 4.8859
294/300, train_loss: 3.4482
295/300, train_loss: 0.1545
296/300, train_loss: 6.3323
297/300, train_loss: 1.2757
298/300, train_loss: 1.0412
299/300, train_loss: 2.9079
300/300, train_loss: 1.5391
epoch 6 average loss: 3.8717
Current epoch: 6 current accuracy: 0.0469
Best accuracy: 0.0469 at epoch 2
----------
epoch 7/150
1/300, train_loss: 1.3445
2/300, train_loss: 2.5883
3/300, train_loss: 6.0481
4/300, train_loss: 0.6203
5/300, train_loss: 2.3491
6/300, train_loss: 3.6614
7/300, train_loss: 4.9025
8/300, train_loss: 3.3995
9/300, train_loss: 10.4761
10/300, train_loss: 3.7768
11/300, train_loss: 0.0071
12/300, train_loss: 2.3225
13/300, train_loss: 2.4138
14/300, train_loss: 0.7452
15/300, train_loss: 3.6273
16/300, train_loss: 4.4299
17/300, train_loss: 0.2073
18/300, train_loss: 3.6263
19/300, train_loss: 7.1626
20/300, train_loss: 1.2116
21/300, train_loss: 2.1230
22/300, train_loss: 1.9184
23/300, train_loss: 5.4712
24/300, train_loss: 2.2603
25/300, train_loss: 1.2634
26/300, train_loss: 3.1732
27/300, train_loss: 4.3743
28/300, train_loss: 7.8502
29/300, train_loss: 2.5854
30/300, train_loss: 0.9827
31/300, train_loss: 5.8956
32/300, train_loss: 3.6422
33/300, train_loss: 3.3102
34/300, train_loss: 8.5901
35/300, train_loss: 0.9018
36/300, train_loss: 3.5840
37/300, train_loss: 4.4589
38/300, train_loss: 2.4157
39/300, train_loss: 1.9061
40/300, train_loss: 3.6426
41/300, train_loss: 10.3467
42/300, train_loss: 1.2589
43/300, train_loss: 3.5344
44/300, train_loss: 1.4695
45/300, train_loss: 1.2479
46/300, train_loss: 5.9302
47/300, train_loss: 1.9435
48/300, train_loss: 2.6199
49/300, train_loss: 3.6885
50/300, train_loss: 2.6398
51/300, train_loss: 1.2446
52/300, train_loss: 2.8191
53/300, train_loss: 7.7118
54/300, train_loss: 3.3283
55/300, train_loss: 0.9659
56/300, train_loss: 7.9370
57/300, train_loss: 4.9079
58/300, train_loss: 5.7486
59/300, train_loss: 5.3147
60/300, train_loss: 1.5104
61/300, train_loss: 3.6002
62/300, train_loss: 0.7917
63/300, train_loss: 3.8515
64/300, train_loss: 6.9945
65/300, train_loss: 5.8869
66/300, train_loss: 1.3356
67/300, train_loss: 9.3971
68/300, train_loss: 6.0508
69/300, train_loss: 3.3251
70/300, train_loss: 3.6543
71/300, train_loss: 7.1952
72/300, train_loss: 4.5282
73/300, train_loss: 5.0510
74/300, train_loss: 1.6569
75/300, train_loss: 2.2152
76/300, train_loss: 3.8524
77/300, train_loss: 5.3101
78/300, train_loss: 3.1521
79/300, train_loss: 0.1203
80/300, train_loss: 1.6691
81/300, train_loss: 1.4917
82/300, train_loss: 7.3972
83/300, train_loss: 5.2051
84/300, train_loss: 5.0949
85/300, train_loss: 5.0658
86/300, train_loss: 1.4403
87/300, train_loss: 4.2366
88/300, train_loss: 2.8145
89/300, train_loss: 5.7997
90/300, train_loss: 6.4367
91/300, train_loss: 6.9425
92/300, train_loss: 5.5219
93/300, train_loss: 2.9064
94/300, train_loss: 2.3189
95/300, train_loss: 2.0757
96/300, train_loss: 1.8438
97/300, train_loss: 1.7680
98/300, train_loss: 5.0807
99/300, train_loss: 6.2690
100/300, train_loss: 8.5997
101/300, train_loss: 3.3313
102/300, train_loss: 5.4831
103/300, train_loss: 1.6145
104/300, train_loss: 4.3932
105/300, train_loss: 2.3229
106/300, train_loss: 0.1437
107/300, train_loss: 1.4103
108/300, train_loss: 4.9725
109/300, train_loss: 4.5095
110/300, train_loss: 3.4220
111/300, train_loss: 4.8494
112/300, train_loss: 5.3805
113/300, train_loss: 8.0166
114/300, train_loss: 0.8796
115/300, train_loss: 6.9639
116/300, train_loss: 3.6497
117/300, train_loss: 3.4050
118/300, train_loss: 2.5659
119/300, train_loss: 1.7986
120/300, train_loss: 0.8782
121/300, train_loss: 0.5966
122/300, train_loss: 3.8220
123/300, train_loss: 3.0262
124/300, train_loss: 5.8672
125/300, train_loss: 2.2330
126/300, train_loss: 5.6093
127/300, train_loss: 3.0149
128/300, train_loss: 1.1814
129/300, train_loss: 9.4664
130/300, train_loss: 3.9413
131/300, train_loss: 5.9852
132/300, train_loss: 5.8061
133/300, train_loss: 4.3839
134/300, train_loss: 4.4920
135/300, train_loss: 3.4957
136/300, train_loss: 0.8854
137/300, train_loss: 4.9900
138/300, train_loss: 1.3651
139/300, train_loss: 5.4477
140/300, train_loss: 0.3049
141/300, train_loss: 0.9941
142/300, train_loss: 0.4259
143/300, train_loss: 5.8214
144/300, train_loss: 4.0237
145/300, train_loss: 10.1909
146/300, train_loss: 1.7066
147/300, train_loss: 2.0529
148/300, train_loss: 6.1766
149/300, train_loss: 3.0149
150/300, train_loss: 2.3601
151/300, train_loss: 3.4245
152/300, train_loss: 1.1624
153/300, train_loss: 4.2595
154/300, train_loss: 7.0804
155/300, train_loss: 1.7021
156/300, train_loss: 0.0611
157/300, train_loss: 5.1857
158/300, train_loss: 1.9243
159/300, train_loss: 4.0642
160/300, train_loss: 0.4945
161/300, train_loss: 5.0045
162/300, train_loss: 4.8014
163/300, train_loss: 1.3414
164/300, train_loss: 2.4543
165/300, train_loss: 2.4098
166/300, train_loss: 4.3561
167/300, train_loss: 4.9519
168/300, train_loss: 8.0228
169/300, train_loss: 2.8496
170/300, train_loss: 5.4744
171/300, train_loss: 1.7336
172/300, train_loss: 4.5141
173/300, train_loss: 3.1707
174/300, train_loss: 1.2556
175/300, train_loss: 3.1888
176/300, train_loss: 1.4170
177/300, train_loss: 4.7134
178/300, train_loss: 3.8297
179/300, train_loss: 4.1834
180/300, train_loss: 2.1292
181/300, train_loss: 4.3056
182/300, train_loss: 2.7197
183/300, train_loss: 9.0648
184/300, train_loss: 2.6250
185/300, train_loss: 1.4855
186/300, train_loss: 7.0812
187/300, train_loss: 3.9948
188/300, train_loss: 1.8725
189/300, train_loss: 7.4336
190/300, train_loss: 7.4774
191/300, train_loss: 5.3354
192/300, train_loss: 9.5172
193/300, train_loss: 5.7744
194/300, train_loss: 5.6478
195/300, train_loss: 3.8107
196/300, train_loss: 2.7390
197/300, train_loss: 3.3270
198/300, train_loss: 4.1781
199/300, train_loss: 0.2509
200/300, train_loss: 4.2911
201/300, train_loss: 0.8597
202/300, train_loss: 3.3243
203/300, train_loss: 2.6113
204/300, train_loss: 1.3458
205/300, train_loss: 3.9417
206/300, train_loss: 5.2187
207/300, train_loss: 4.8957
208/300, train_loss: 4.1819
209/300, train_loss: 3.2302
210/300, train_loss: 5.7957
211/300, train_loss: 6.2634
212/300, train_loss: 2.6902
213/300, train_loss: 3.6065
214/300, train_loss: 5.7856
215/300, train_loss: 4.6285
216/300, train_loss: 5.1970
217/300, train_loss: 3.5927
218/300, train_loss: 5.7929
219/300, train_loss: 2.0734
220/300, train_loss: 4.3571
221/300, train_loss: 3.8748
222/300, train_loss: 0.6368
223/300, train_loss: 1.6235
224/300, train_loss: 1.9324
225/300, train_loss: 0.4120
226/300, train_loss: 4.0955
227/300, train_loss: 0.2503
228/300, train_loss: 5.2776
229/300, train_loss: 3.2489
230/300, train_loss: 2.8059
231/300, train_loss: 0.8379
232/300, train_loss: 0.8865
233/300, train_loss: 9.3218
234/300, train_loss: 1.6306
235/300, train_loss: 2.1145
236/300, train_loss: 2.1668
237/300, train_loss: 1.3078
238/300, train_loss: 6.2939
239/300, train_loss: 3.1718
240/300, train_loss: 2.8222
241/300, train_loss: 5.4236
242/300, train_loss: 3.0467
243/300, train_loss: 0.9275
244/300, train_loss: 3.9137
245/300, train_loss: 3.1970
246/300, train_loss: 0.1038
247/300, train_loss: 2.9242
248/300, train_loss: 3.2494
249/300, train_loss: 5.7741
250/300, train_loss: 1.1708
251/300, train_loss: 1.5025
252/300, train_loss: 3.7293
253/300, train_loss: 3.6346
254/300, train_loss: 4.8854
255/300, train_loss: 2.8243
256/300, train_loss: 6.0015
257/300, train_loss: 1.1016
258/300, train_loss: 8.1504
259/300, train_loss: 1.0318
260/300, train_loss: 7.4814
261/300, train_loss: 4.8667
262/300, train_loss: 1.8443
263/300, train_loss: 3.3716
264/300, train_loss: 1.8719
265/300, train_loss: 3.4177
266/300, train_loss: 3.3244
267/300, train_loss: 2.8638
268/300, train_loss: 2.5753
269/300, train_loss: 3.2394
270/300, train_loss: 3.2670
271/300, train_loss: 7.1524
272/300, train_loss: 3.4816
273/300, train_loss: 1.5317
274/300, train_loss: 2.4993
275/300, train_loss: 4.3824
276/300, train_loss: 2.6991
277/300, train_loss: 5.9927
278/300, train_loss: 4.1084
279/300, train_loss: 0.8818
280/300, train_loss: 6.9824
281/300, train_loss: 0.7600
282/300, train_loss: 5.5211
283/300, train_loss: 6.7061
284/300, train_loss: 0.9644
285/300, train_loss: 4.4880
286/300, train_loss: 8.3217
287/300, train_loss: 3.0302
288/300, train_loss: 5.6775
289/300, train_loss: 2.4071
290/300, train_loss: 4.2864
291/300, train_loss: 4.9289
292/300, train_loss: 0.9176
293/300, train_loss: 1.9435
294/300, train_loss: 4.3585
295/300, train_loss: 5.6990
296/300, train_loss: 1.1388
297/300, train_loss: 1.1080
298/300, train_loss: 6.7881
299/300, train_loss: 2.8146
300/300, train_loss: 7.3369
epoch 7 average loss: 3.6996
----------
epoch 8/150
1/300, train_loss: 4.9842
2/300, train_loss: 2.3340
3/300, train_loss: 5.2007
4/300, train_loss: 2.9408
5/300, train_loss: 0.7067
6/300, train_loss: 8.6685
7/300, train_loss: 8.0369
8/300, train_loss: 0.5426
9/300, train_loss: 0.0911
10/300, train_loss: 1.6364
11/300, train_loss: 6.1896
12/300, train_loss: 4.9352
13/300, train_loss: 4.6045
14/300, train_loss: 2.8275
15/300, train_loss: 1.5607
16/300, train_loss: 2.0104
17/300, train_loss: 8.6058
18/300, train_loss: 1.1871
19/300, train_loss: 1.3757
20/300, train_loss: 9.6562
21/300, train_loss: 2.9541
22/300, train_loss: 1.8405
23/300, train_loss: 0.2273
24/300, train_loss: 3.8561
25/300, train_loss: 3.3275
26/300, train_loss: 4.1085
27/300, train_loss: 1.3220
28/300, train_loss: 7.9579
29/300, train_loss: 3.9632
30/300, train_loss: 1.4683
31/300, train_loss: 1.4943
32/300, train_loss: 4.4390
33/300, train_loss: 0.4019
34/300, train_loss: 6.7174
35/300, train_loss: 5.9776
36/300, train_loss: 1.5229
37/300, train_loss: 3.2329
38/300, train_loss: 0.4697
39/300, train_loss: 1.5990
40/300, train_loss: 2.2148
41/300, train_loss: 4.4145
42/300, train_loss: 0.0252
43/300, train_loss: 8.4481
44/300, train_loss: 7.6790
45/300, train_loss: 2.4669
46/300, train_loss: 7.1091
47/300, train_loss: 1.8480
48/300, train_loss: 7.7519
49/300, train_loss: 7.0686
50/300, train_loss: 4.7898
51/300, train_loss: 2.4965
52/300, train_loss: 8.5442
53/300, train_loss: 2.9418
54/300, train_loss: 2.5236
55/300, train_loss: 5.5823
56/300, train_loss: 3.7353
57/300, train_loss: 3.6882
58/300, train_loss: 3.3996
59/300, train_loss: 2.1652
60/300, train_loss: 4.0447
61/300, train_loss: 0.3933
62/300, train_loss: 3.9919
63/300, train_loss: 2.7931
64/300, train_loss: 0.7976
65/300, train_loss: 0.5385
66/300, train_loss: 4.8891
67/300, train_loss: 3.5040
68/300, train_loss: 9.0800
69/300, train_loss: 4.6303
70/300, train_loss: 3.3105
71/300, train_loss: 5.0191
72/300, train_loss: 5.1083
73/300, train_loss: 1.7294
74/300, train_loss: 2.4814
75/300, train_loss: 5.6491
76/300, train_loss: 1.8098
77/300, train_loss: 1.4045
78/300, train_loss: 3.1430
79/300, train_loss: 4.2574
80/300, train_loss: 6.3926
81/300, train_loss: 6.7174
82/300, train_loss: 1.0107
83/300, train_loss: 0.8906
84/300, train_loss: 5.1042
85/300, train_loss: 5.4926
86/300, train_loss: 3.4365
87/300, train_loss: 6.7911
88/300, train_loss: 0.3916
89/300, train_loss: 1.3139
90/300, train_loss: 3.4867
91/300, train_loss: 4.5659
92/300, train_loss: 0.5670
93/300, train_loss: 5.2006
94/300, train_loss: 4.4939
95/300, train_loss: 1.6909
96/300, train_loss: 3.0025
97/300, train_loss: 4.9248
98/300, train_loss: 5.6227
99/300, train_loss: 3.6195
100/300, train_loss: 0.4385
101/300, train_loss: 9.0075
102/300, train_loss: 3.7035
103/300, train_loss: 0.9897
104/300, train_loss: 2.3863
105/300, train_loss: 1.9851
106/300, train_loss: 2.4997
107/300, train_loss: 6.2012
108/300, train_loss: 8.7367
109/300, train_loss: 4.5518
110/300, train_loss: 1.9592
111/300, train_loss: 5.3368
112/300, train_loss: 2.8452
113/300, train_loss: 2.4367
114/300, train_loss: 3.3673
115/300, train_loss: 4.2666
116/300, train_loss: 5.4653
117/300, train_loss: 6.4840
118/300, train_loss: 1.2365
119/300, train_loss: 3.1892
120/300, train_loss: 3.9993
121/300, train_loss: 2.5746
122/300, train_loss: 3.3273
123/300, train_loss: 5.7485
124/300, train_loss: 4.2036
125/300, train_loss: 2.3156
126/300, train_loss: 4.3868
127/300, train_loss: 3.3182
128/300, train_loss: 6.7859
129/300, train_loss: 3.0897
130/300, train_loss: 3.2003
131/300, train_loss: 6.5996
132/300, train_loss: 3.3594
133/300, train_loss: 2.9155
134/300, train_loss: 2.6395
135/300, train_loss: 1.6479
136/300, train_loss: 1.9897
137/300, train_loss: 5.8457
138/300, train_loss: 8.6748
139/300, train_loss: 5.8281
140/300, train_loss: 1.1209
141/300, train_loss: 4.3699
142/300, train_loss: 7.2499
143/300, train_loss: 0.5701
144/300, train_loss: 3.1151
145/300, train_loss: 5.5012
146/300, train_loss: 1.0994
147/300, train_loss: 4.5361
148/300, train_loss: 3.2279
149/300, train_loss: 4.7868
150/300, train_loss: 3.3678
151/300, train_loss: 1.7228
152/300, train_loss: 4.9592
153/300, train_loss: 0.8381
154/300, train_loss: 0.9424
155/300, train_loss: 7.7635
156/300, train_loss: 1.9634
157/300, train_loss: 3.2284
158/300, train_loss: 4.4976
159/300, train_loss: 1.3635
160/300, train_loss: 3.6547
161/300, train_loss: 4.6808
162/300, train_loss: 5.9912
163/300, train_loss: 1.6293
164/300, train_loss: 1.8025
165/300, train_loss: 9.3671
166/300, train_loss: 3.2466
167/300, train_loss: 2.9785
168/300, train_loss: 9.0883
169/300, train_loss: 2.7061
170/300, train_loss: 6.2975
171/300, train_loss: 3.7282
172/300, train_loss: 8.5741
173/300, train_loss: 3.4869
174/300, train_loss: 0.1441
175/300, train_loss: 5.9108
176/300, train_loss: 4.2703
177/300, train_loss: 0.4120
178/300, train_loss: 3.1027
179/300, train_loss: 5.2342
180/300, train_loss: 8.4453
181/300, train_loss: 1.9871
182/300, train_loss: 0.7824
183/300, train_loss: 3.5021
184/300, train_loss: 2.5012
185/300, train_loss: 1.6919
186/300, train_loss: 6.0592
187/300, train_loss: 3.4043
188/300, train_loss: 2.6790
189/300, train_loss: 2.6151
190/300, train_loss: 4.4933
191/300, train_loss: 5.2957
192/300, train_loss: 2.8122
193/300, train_loss: 6.4551
194/300, train_loss: 9.1726
195/300, train_loss: 5.3980
196/300, train_loss: 5.8144
197/300, train_loss: 0.7981
198/300, train_loss: 4.5503
199/300, train_loss: 2.0794
200/300, train_loss: 5.4736
201/300, train_loss: 6.3090
202/300, train_loss: 8.6306
203/300, train_loss: 1.6624
204/300, train_loss: 6.1872
205/300, train_loss: 0.5493
206/300, train_loss: 2.2123
207/300, train_loss: 2.8903
208/300, train_loss: 4.0110
209/300, train_loss: 5.3309
210/300, train_loss: 2.0810
211/300, train_loss: 1.5178
212/300, train_loss: 0.8988
213/300, train_loss: 1.7608
214/300, train_loss: 10.1496
215/300, train_loss: 2.9374
216/300, train_loss: 3.9232
217/300, train_loss: 2.9495
218/300, train_loss: 7.7285
219/300, train_loss: 1.1103
220/300, train_loss: 8.1275
221/300, train_loss: 1.1625
222/300, train_loss: 7.3803
223/300, train_loss: 3.6373
224/300, train_loss: 6.5974
225/300, train_loss: 7.4615
226/300, train_loss: 5.5142
227/300, train_loss: 7.1786
228/300, train_loss: 2.2004
229/300, train_loss: 6.5439
230/300, train_loss: 1.1506
231/300, train_loss: 7.0187
232/300, train_loss: 7.2879
233/300, train_loss: 0.6443
234/300, train_loss: 1.9710
235/300, train_loss: 3.6362
236/300, train_loss: 4.3160
237/300, train_loss: 1.7220
238/300, train_loss: 4.4311
239/300, train_loss: 2.0282
240/300, train_loss: 9.0946
241/300, train_loss: 3.2922
242/300, train_loss: 6.5809
243/300, train_loss: 2.3125
244/300, train_loss: 1.2359
245/300, train_loss: 3.6828
246/300, train_loss: 3.2548
247/300, train_loss: 10.6155
248/300, train_loss: 1.4041
249/300, train_loss: 6.4822
250/300, train_loss: 6.9844
251/300, train_loss: 3.3827
252/300, train_loss: 5.6527
253/300, train_loss: 4.1984
254/300, train_loss: 6.5460
255/300, train_loss: 5.2826
256/300, train_loss: 0.7828
257/300, train_loss: 5.5069
258/300, train_loss: 6.2386
259/300, train_loss: 3.7167
260/300, train_loss: 7.0842
261/300, train_loss: 1.4396
262/300, train_loss: 4.2293
263/300, train_loss: 3.9986
264/300, train_loss: 6.2144
265/300, train_loss: 0.9825
266/300, train_loss: 5.7776
267/300, train_loss: 5.0608
268/300, train_loss: 2.6807
269/300, train_loss: 2.7944
270/300, train_loss: 4.9863
271/300, train_loss: 8.5196
272/300, train_loss: 2.0918
273/300, train_loss: 2.3059
274/300, train_loss: 5.0175
275/300, train_loss: 3.2714
276/300, train_loss: 6.4187
277/300, train_loss: 3.6435
278/300, train_loss: 3.4462
279/300, train_loss: 4.9160
280/300, train_loss: 1.6229
281/300, train_loss: 5.9588
282/300, train_loss: 3.0889
283/300, train_loss: 10.6959
284/300, train_loss: 4.5048
285/300, train_loss: 3.3404
286/300, train_loss: 5.3655
287/300, train_loss: 1.1599
288/300, train_loss: 3.5615
289/300, train_loss: 9.2672
290/300, train_loss: 10.6738
291/300, train_loss: 3.4873
292/300, train_loss: 5.1600
293/300, train_loss: 2.7519
294/300, train_loss: 0.3610
295/300, train_loss: 10.3519
296/300, train_loss: 5.5058
297/300, train_loss: 5.9039
298/300, train_loss: 3.8998
299/300, train_loss: 7.2683
300/300, train_loss: 1.0804
epoch 8 average loss: 4.0474
Current epoch: 8 current accuracy: 0.0469
Best accuracy: 0.0469 at epoch 2
----------
epoch 9/150
1/300, train_loss: 2.7751
2/300, train_loss: 4.0599
3/300, train_loss: 2.5157
4/300, train_loss: 0.7478
5/300, train_loss: 7.0866
6/300, train_loss: 5.1869
7/300, train_loss: 1.7008
8/300, train_loss: 1.7564
9/300, train_loss: 1.2118
10/300, train_loss: 1.2801
11/300, train_loss: 2.4996
12/300, train_loss: 0.2168
13/300, train_loss: 3.2144
14/300, train_loss: 6.0167
15/300, train_loss: 1.9199
16/300, train_loss: 5.8166
17/300, train_loss: 4.9191
18/300, train_loss: 5.0780
19/300, train_loss: 5.2897
20/300, train_loss: 0.4882
21/300, train_loss: 0.3379
22/300, train_loss: 1.1595
23/300, train_loss: 0.8508
24/300, train_loss: 1.4342
25/300, train_loss: 5.0221
26/300, train_loss: 2.8715
27/300, train_loss: 3.7007
28/300, train_loss: 3.5823
29/300, train_loss: 8.9688
30/300, train_loss: 8.0928
31/300, train_loss: 8.8549
32/300, train_loss: 1.8128
33/300, train_loss: 1.5459
34/300, train_loss: 4.2632
35/300, train_loss: 3.7405
36/300, train_loss: 5.4019
37/300, train_loss: 2.8458
38/300, train_loss: 4.3172
39/300, train_loss: 5.6902
40/300, train_loss: 6.9447
41/300, train_loss: 2.5850
42/300, train_loss: 2.3135
43/300, train_loss: 2.8808
44/300, train_loss: 7.1658
45/300, train_loss: 0.9707
46/300, train_loss: 4.8119
47/300, train_loss: 2.2015
48/300, train_loss: 0.0711
49/300, train_loss: 4.5961
50/300, train_loss: 1.4080
51/300, train_loss: 10.6211
52/300, train_loss: 5.0606
53/300, train_loss: 0.0064
54/300, train_loss: 3.9007
55/300, train_loss: 3.9233
56/300, train_loss: 6.3655
57/300, train_loss: 0.5032
58/300, train_loss: 4.2616
59/300, train_loss: 6.1335
60/300, train_loss: 5.3368
61/300, train_loss: 2.1168
62/300, train_loss: 3.1482
63/300, train_loss: 1.1139
64/300, train_loss: 5.2831
65/300, train_loss: 2.8260
66/300, train_loss: 2.1154
67/300, train_loss: 3.5117
68/300, train_loss: 2.9846
69/300, train_loss: 2.0161
70/300, train_loss: 1.1586
71/300, train_loss: 3.5520
72/300, train_loss: 1.6564
73/300, train_loss: 5.6842
74/300, train_loss: 4.8320
75/300, train_loss: 2.1207
76/300, train_loss: 1.8696
77/300, train_loss: 2.7211
78/300, train_loss: 4.1938
79/300, train_loss: 2.5680
80/300, train_loss: 3.0189
81/300, train_loss: 3.7368
82/300, train_loss: 3.5304
83/300, train_loss: 4.2666
84/300, train_loss: 4.4281
85/300, train_loss: 3.8781
86/300, train_loss: 0.4629
87/300, train_loss: 4.5202
88/300, train_loss: 7.9036
89/300, train_loss: 2.5896
90/300, train_loss: 5.6183
91/300, train_loss: 2.4711
92/300, train_loss: 8.4235
93/300, train_loss: 0.9735
94/300, train_loss: 0.6130
95/300, train_loss: 2.5578
96/300, train_loss: 5.3521
97/300, train_loss: 2.8917
98/300, train_loss: 6.4006
99/300, train_loss: 3.1359
100/300, train_loss: 3.7453
101/300, train_loss: 5.2056
102/300, train_loss: 2.3049
103/300, train_loss: 9.0644
104/300, train_loss: 1.5954
105/300, train_loss: 0.3280
106/300, train_loss: 4.4604
107/300, train_loss: 0.5365
108/300, train_loss: 2.9897
109/300, train_loss: 6.0717
110/300, train_loss: 10.4228
111/300, train_loss: 3.0148
112/300, train_loss: 3.8223
113/300, train_loss: 1.6880
114/300, train_loss: 5.9628
115/300, train_loss: 0.2697
116/300, train_loss: 1.1232
117/300, train_loss: 10.6710
118/300, train_loss: 3.3747
119/300, train_loss: 2.4096
120/300, train_loss: 0.7960
121/300, train_loss: 1.7785
122/300, train_loss: 0.0037
123/300, train_loss: 1.6713
124/300, train_loss: 5.6458
125/300, train_loss: 4.2722
126/300, train_loss: 4.7180
127/300, train_loss: 8.2822
128/300, train_loss: 2.5772
129/300, train_loss: 1.5829
130/300, train_loss: 2.2036
131/300, train_loss: 3.2579
132/300, train_loss: 4.2774
133/300, train_loss: 6.2455
134/300, train_loss: 3.8658
135/300, train_loss: 4.8495
136/300, train_loss: 3.7844
137/300, train_loss: 6.4362
138/300, train_loss: 2.4145
139/300, train_loss: 1.7013
140/300, train_loss: 6.8459
141/300, train_loss: 3.4399
142/300, train_loss: 4.9086
143/300, train_loss: 2.6605
144/300, train_loss: 11.3862
145/300, train_loss: 1.8326
146/300, train_loss: 0.2496
147/300, train_loss: 2.1522
148/300, train_loss: 5.3494
149/300, train_loss: 2.8606
150/300, train_loss: 1.1426
151/300, train_loss: 8.9679
152/300, train_loss: 0.3346
153/300, train_loss: 0.3975
154/300, train_loss: 2.4620
155/300, train_loss: 6.1197
156/300, train_loss: 3.8846
157/300, train_loss: 3.4196
158/300, train_loss: 6.7272
159/300, train_loss: 4.5866
160/300, train_loss: 5.4486
161/300, train_loss: 2.5151
162/300, train_loss: 0.7733
163/300, train_loss: 8.2504
164/300, train_loss: 4.9548
165/300, train_loss: 7.1517
166/300, train_loss: 5.5874
167/300, train_loss: 3.6258
168/300, train_loss: 0.7599
169/300, train_loss: 1.2429
170/300, train_loss: 5.9163
171/300, train_loss: 6.6713
172/300, train_loss: 0.5178
173/300, train_loss: 2.5481
174/300, train_loss: 4.0586
175/300, train_loss: 3.5103
176/300, train_loss: 8.6586
177/300, train_loss: 0.2028
178/300, train_loss: 1.2312
179/300, train_loss: 5.2710
180/300, train_loss: 4.4572
181/300, train_loss: 3.8902
182/300, train_loss: 3.2445
183/300, train_loss: 2.1498
184/300, train_loss: 3.6497
185/300, train_loss: 2.8356
186/300, train_loss: 6.8731
187/300, train_loss: 3.7667
188/300, train_loss: 7.0483
189/300, train_loss: 8.8895
190/300, train_loss: 3.2954
191/300, train_loss: 2.6200
192/300, train_loss: 7.5194
193/300, train_loss: 4.7610
194/300, train_loss: 1.7581
195/300, train_loss: 3.0786
196/300, train_loss: 7.1577
197/300, train_loss: 8.4721
198/300, train_loss: 4.9200
199/300, train_loss: 3.6832
200/300, train_loss: 1.4059
201/300, train_loss: 5.3781
202/300, train_loss: 3.9510
203/300, train_loss: 4.2521
204/300, train_loss: 1.5550
205/300, train_loss: 6.9819
206/300, train_loss: 9.0223
207/300, train_loss: 3.4030
208/300, train_loss: 1.3969
209/300, train_loss: 4.6540
210/300, train_loss: 4.9758
211/300, train_loss: 5.8754
212/300, train_loss: 6.0288
213/300, train_loss: 6.5496
214/300, train_loss: 3.2001
215/300, train_loss: 3.6443
216/300, train_loss: 3.5397
217/300, train_loss: 5.6549
218/300, train_loss: 6.4382
219/300, train_loss: 7.4423
220/300, train_loss: 1.6335
221/300, train_loss: 3.0718
222/300, train_loss: 1.4902
223/300, train_loss: 2.0521
224/300, train_loss: 2.8716
225/300, train_loss: 3.8282
226/300, train_loss: 1.1714
227/300, train_loss: 2.9249
228/300, train_loss: 1.1107
229/300, train_loss: 3.3024
230/300, train_loss: 3.5534
231/300, train_loss: 0.1928
232/300, train_loss: 4.6348
233/300, train_loss: 1.5744
234/300, train_loss: 3.1929
235/300, train_loss: 4.1888
236/300, train_loss: 2.0040
237/300, train_loss: 8.5221
238/300, train_loss: 5.3342
239/300, train_loss: 2.9187
240/300, train_loss: 4.2557
241/300, train_loss: 2.9779
242/300, train_loss: 6.7207
243/300, train_loss: 4.3711
244/300, train_loss: 3.7320
245/300, train_loss: 1.7106
246/300, train_loss: 4.9459
247/300, train_loss: 2.0210
248/300, train_loss: 6.1179
249/300, train_loss: 1.2699
250/300, train_loss: 3.6126
251/300, train_loss: 7.4685
252/300, train_loss: 1.5184
253/300, train_loss: 7.1973
254/300, train_loss: 2.9149
255/300, train_loss: 1.3814
256/300, train_loss: 6.6454
257/300, train_loss: 1.0911
258/300, train_loss: 4.6459
259/300, train_loss: 0.9961
260/300, train_loss: 1.4481
261/300, train_loss: 1.4485
262/300, train_loss: 5.7813
263/300, train_loss: 7.7022
264/300, train_loss: 4.8108
265/300, train_loss: 1.7802
266/300, train_loss: 3.1312
267/300, train_loss: 1.5009
268/300, train_loss: 7.4140
269/300, train_loss: 1.8272
270/300, train_loss: 2.9139
271/300, train_loss: 5.4001
272/300, train_loss: 5.0025
273/300, train_loss: 3.1054
274/300, train_loss: 2.0367
275/300, train_loss: 0.1660
276/300, train_loss: 0.0798
277/300, train_loss: 1.7392
278/300, train_loss: 3.1751
279/300, train_loss: 2.6646
280/300, train_loss: 2.5141
281/300, train_loss: 3.2332
282/300, train_loss: 9.0976
283/300, train_loss: 1.1286
284/300, train_loss: 0.7027
285/300, train_loss: 1.3824
286/300, train_loss: 2.7458
287/300, train_loss: 6.3968
288/300, train_loss: 1.5622
289/300, train_loss: 9.7886
290/300, train_loss: 5.4269
291/300, train_loss: 0.4917
292/300, train_loss: 7.7107
293/300, train_loss: 6.2709
294/300, train_loss: 5.5696
295/300, train_loss: 7.9694
296/300, train_loss: 9.6871
297/300, train_loss: 3.5856
298/300, train_loss: 1.7590
